{"config":{"indexing":"full","lang":["en","es"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome Welcome to the Learning Lab, a platform dedicated to empowering you in the seamless integration of NeuralSeek with your selected KnowledgeBase and Virtual Agent. Throughout this lab, you will learn to harness NeuralSeek's sophisticated AI capabilities, which will elevate your virtual agent to the forefront of natural language generation. We will go through step-by-step integration of NeuralSeek with a KnowledgeBase and Virtual Agent, fine-tune AI-generated answers using the tools and metrics on the NeuralSeek user interface, and explore the powerful mAIstro playground which is #1 in retrieval augmented generation for enterprise. By seamlessly incorporating NeuralSeek, you'll discover how to ensure that your virtual agent's responses not only uphold accuracy but also amplify scalability, all while retaining the essential element of human oversight. Unlock the full potential of AI with no code, minimal effort and all the necessary enterprise functionality and security. Module 1: Configuration and Integration This module provides a step-by-step guide for seamlessly integrating NeuralSeek with your chosen cloud provider's KnowledgeBase and custom virtual agent. Level: Entry Time: 20 minutes No Code Required Module 2: Seeking Answers This module showcases NeuralSeek's pivotal features for training virtual agents, ensuring accurate natural language responses, and safeguarding user privacy all with built-in tools for human oversight to maintain data integrity. Level: Intermediate Time: 20 minutes No Code Required Module 3: Exploring mAIstro This module offers a dynamic content creation and retrieval platform, featuring advanced RAG capabilities, expert guidance on LLM prompt syntax, and data quality enhancement tools to facilitate seamless interaction with Large Language Models for refined content generation without coding. Level: Advanced Time: 20 minutes No Code Required","title":"Getting Started"},{"location":"#welcome","text":"Welcome to the Learning Lab, a platform dedicated to empowering you in the seamless integration of NeuralSeek with your selected KnowledgeBase and Virtual Agent. Throughout this lab, you will learn to harness NeuralSeek's sophisticated AI capabilities, which will elevate your virtual agent to the forefront of natural language generation. We will go through step-by-step integration of NeuralSeek with a KnowledgeBase and Virtual Agent, fine-tune AI-generated answers using the tools and metrics on the NeuralSeek user interface, and explore the powerful mAIstro playground which is #1 in retrieval augmented generation for enterprise. By seamlessly incorporating NeuralSeek, you'll discover how to ensure that your virtual agent's responses not only uphold accuracy but also amplify scalability, all while retaining the essential element of human oversight. Unlock the full potential of AI with no code, minimal effort and all the necessary enterprise functionality and security.","title":"Welcome"},{"location":"#module-1-configuration-and-integration","text":"This module provides a step-by-step guide for seamlessly integrating NeuralSeek with your chosen cloud provider's KnowledgeBase and custom virtual agent. Level: Entry Time: 20 minutes No Code Required","title":"Module 1: Configuration and Integration"},{"location":"#module-2-seeking-answers","text":"This module showcases NeuralSeek's pivotal features for training virtual agents, ensuring accurate natural language responses, and safeguarding user privacy all with built-in tools for human oversight to maintain data integrity. Level: Intermediate Time: 20 minutes No Code Required","title":"Module 2: Seeking Answers"},{"location":"#module-3-exploring-maistro","text":"This module offers a dynamic content creation and retrieval platform, featuring advanced RAG capabilities, expert guidance on LLM prompt syntax, and data quality enhancement tools to facilitate seamless interaction with Large Language Models for refined content generation without coding. Level: Advanced Time: 20 minutes No Code Required","title":"Module 3: Exploring mAIstro"},{"location":"additional_info/aws_LLM/aws_module1-4/","text":"Connect a Large Language Model (LLM) with NeuralSeek Enhance your NeuralSeek experience by following these instructions to seamlessly add at least one LLM (Large Language Model) to optimize its functionalities. If you add more than one, NeuralSeek will balance them for functions that can use multiple LLMs. If an LLM can't handle certain features, those features won't be available. If you don't add an LLM for a function, that part of NeuralSeek won't work. \u26a0 In order to configure a LLM, make sure that you have subscribed to the Bring Your Own LLM (BYOLLM) plan. All other plans will default to NeuralSeek\u2019s curated LLM, and this option will not be available. Remember, it is the responsibility of each participant to understand and manage the associated costs related to the use of NeuralSeek and any other integrated services within their AWS environment. Add an LLM Navigate to the NeuralSeek user interface. In the \"Home\" tab, follow the steps to connect to your LLM. \u26a0\ufe0f You must add at least one LLM. (a) Click \"Add an LLM\". Platform and LLM Selection For AWS users, it is recommended to connect to the Amazon Bedrock platform, and the Claude v2 LLM selection. (a) Click the drop-down menu to select the LLM platform. For this example, select \" Amazon Bedrock \". (b) Click the drop-down menu to select the LLM. For this example, select \" Claude v2 \". (c) Click \"Add\" to add the LLM. LLM Functions Instructions for generation and location of AWS Access Key information can be found in the AWS Additional Information guide of the lab. Enter the Amazon Bedrock AWS Role Access Key. Enter the Amazon Bedrock AWS Role Secret Access Key. Enter the Amazon Bedrock AWS Region. Enable available LLM languages. NeuralSeek will default to enable all 56 available languages. Select desired LLM functions. NeuralSeek will default to select all available functions. For the purpose of this lab, select the following: PII Detection, Conversation Generation, Entity Extraction, Categorization, Example Generation, Intent Creation, Translate, Fallback Sentiment, and Explore . Test the LLM Click \"Test\" to test the LLM. A Large Language Model is now connected to NeuralSeek. \u26a0\ufe0f LLM's can vary in their capabilities and performances. Some LLM can take up to 30 seconds and longer to generate a full response. Use caution when using in conjunction with a virtual agent platform that imposes a strict timeout.","title":"AWS - Connect LLM"},{"location":"additional_info/aws_LLM/aws_module1-4/#connect-a-large-language-model-llm-with-neuralseek","text":"Enhance your NeuralSeek experience by following these instructions to seamlessly add at least one LLM (Large Language Model) to optimize its functionalities. If you add more than one, NeuralSeek will balance them for functions that can use multiple LLMs. If an LLM can't handle certain features, those features won't be available. If you don't add an LLM for a function, that part of NeuralSeek won't work. \u26a0 In order to configure a LLM, make sure that you have subscribed to the Bring Your Own LLM (BYOLLM) plan. All other plans will default to NeuralSeek\u2019s curated LLM, and this option will not be available. Remember, it is the responsibility of each participant to understand and manage the associated costs related to the use of NeuralSeek and any other integrated services within their AWS environment.","title":"Connect a Large Language Model (LLM) with NeuralSeek"},{"location":"additional_info/aws_LLM/aws_module1-4/#add-an-llm","text":"Navigate to the NeuralSeek user interface. In the \"Home\" tab, follow the steps to connect to your LLM. \u26a0\ufe0f You must add at least one LLM. (a) Click \"Add an LLM\".","title":"Add an LLM"},{"location":"additional_info/aws_LLM/aws_module1-4/#platform-and-llm-selection","text":"For AWS users, it is recommended to connect to the Amazon Bedrock platform, and the Claude v2 LLM selection. (a) Click the drop-down menu to select the LLM platform. For this example, select \" Amazon Bedrock \". (b) Click the drop-down menu to select the LLM. For this example, select \" Claude v2 \". (c) Click \"Add\" to add the LLM.","title":"Platform and LLM Selection"},{"location":"additional_info/aws_LLM/aws_module1-4/#llm-functions","text":"Instructions for generation and location of AWS Access Key information can be found in the AWS Additional Information guide of the lab. Enter the Amazon Bedrock AWS Role Access Key. Enter the Amazon Bedrock AWS Role Secret Access Key. Enter the Amazon Bedrock AWS Region. Enable available LLM languages. NeuralSeek will default to enable all 56 available languages. Select desired LLM functions. NeuralSeek will default to select all available functions. For the purpose of this lab, select the following: PII Detection, Conversation Generation, Entity Extraction, Categorization, Example Generation, Intent Creation, Translate, Fallback Sentiment, and Explore .","title":"LLM Functions"},{"location":"additional_info/aws_LLM/aws_module1-4/#test-the-llm","text":"Click \"Test\" to test the LLM. A Large Language Model is now connected to NeuralSeek. \u26a0\ufe0f LLM's can vary in their capabilities and performances. Some LLM can take up to 30 seconds and longer to generate a full response. Use caution when using in conjunction with a virtual agent platform that imposes a strict timeout.","title":"Test the LLM"},{"location":"additional_info/aws_LLM/kendra_keys/","text":"Setting up AWS Kendra Index and Access Keys This section outlines how to generate the necessary access key information needed for establishing a successful connection between the AWS KnowledgeBase \"Kendra Index\" and NeuralSeek. Access Amazon Kendra Navigate to \"Amazon Kendra\" on your AWS Console account. (a) Click \"Create an Index.\" Specify Index Details Create a new index and IAM Role. (a) Add an Index name. In this example, \" learning-lab \". (b) Click \"Create a New Role\" under the IAM Role drop down menu. (c) Add a Role name. In this example, \" learning-lab \". Click \"Next\" to save a new index and role. Configure User Access Control Set up a way to control who can see which documents by automatically filtering them according to each user ID and user groups. (a) Select option for \"Access Control Settings\". In this example, select \" No \". (b) Select option for \"User-group expansion\". In this example, select \" None \". Click \"Next\" to save user access control preferences. Add Additional Capacity Select desired option for \"Provisioning Editions.\" In this example, select \" Developer edition \". Click \"Next\" to save provisioning edition preference. Review and Create Review the details on the page to ensure correctness. Click \"Create\" to generate a new index and IAM role with specified access settings and provisioning edition. \u26a0\ufe0f Propagating IAM Role and creating the Index can take up to 30 minutes. Kendra Index ID Under the \"Index Setting\" section, copy the unique \" Index ID \" to use as the \"Kendra Index ID\" in the Corporate Knowledge Base Details section of NeuralSeek's Configure tab. Create User Navigate to IAM in the AWS Console. (a) Click \"Users\" on the left sidebar menu. (b) Click \"Create a User\". (c) Add a user name. For this example, \" learninglab-testgroup \". Click \"Next\". Click \"Create Group.\" (e) Add a user group name. For this example, \" learninglab-testgroup \". (f) Select a policy name based on the best use case. For the purpose of this lab, select the \" AmazonKendraReadOnlyAccess \" policy name. (g) Click \"Create user group\", then click \"Next.\" Review the details, then click \"Create User\" to create the user. Create Access Key Navigate to the \"Security Credentials\" tab under the selected user after verifying that the user is added to the correct group. (a) In the \"Access keys\" section, click \"Create access key.\" (b) Select the appropriate \"Use case.\" For this example, select \" Application running outside AWS \". (c) Click \"Next\". Click \"Create access key\" to successfully create an access key. AWS Role Access Keys \u26a0\ufe0f Disclaimer: the secret access key will be accessible only once. It is important to copy the secret access key prior to proceeding. On the \"Retrieve access keys\" page, copy the unique \" Access key \" to use as the \"AWS Role Access Key\" in the Corporate Knowledge Base Details section of NeuralSeek's Configure tab. On the same page, copy the unique \" Secret access key \" to use as the \"AWS Role Secret Access Key\" in the Corporate Knowledge Base Details section of NeuralSeek's Configure tab. Click \"Done\" to successfully add the essential AWS Access Key information into NeuralSeek when configuring the AWS Kendra Index KnowledgeBase.","title":"Access Keys"},{"location":"additional_info/aws_LLM/kendra_keys/#setting-up-aws-kendra-index-and-access-keys","text":"This section outlines how to generate the necessary access key information needed for establishing a successful connection between the AWS KnowledgeBase \"Kendra Index\" and NeuralSeek.","title":"Setting up AWS Kendra Index and Access Keys"},{"location":"additional_info/aws_LLM/kendra_keys/#access-amazon-kendra","text":"Navigate to \"Amazon Kendra\" on your AWS Console account. (a) Click \"Create an Index.\"","title":"Access Amazon Kendra"},{"location":"additional_info/aws_LLM/kendra_keys/#specify-index-details","text":"Create a new index and IAM Role. (a) Add an Index name. In this example, \" learning-lab \". (b) Click \"Create a New Role\" under the IAM Role drop down menu. (c) Add a Role name. In this example, \" learning-lab \". Click \"Next\" to save a new index and role.","title":"Specify Index Details"},{"location":"additional_info/aws_LLM/kendra_keys/#configure-user-access-control","text":"Set up a way to control who can see which documents by automatically filtering them according to each user ID and user groups. (a) Select option for \"Access Control Settings\". In this example, select \" No \". (b) Select option for \"User-group expansion\". In this example, select \" None \". Click \"Next\" to save user access control preferences.","title":"Configure User Access Control"},{"location":"additional_info/aws_LLM/kendra_keys/#add-additional-capacity","text":"Select desired option for \"Provisioning Editions.\" In this example, select \" Developer edition \". Click \"Next\" to save provisioning edition preference.","title":"Add Additional Capacity"},{"location":"additional_info/aws_LLM/kendra_keys/#review-and-create","text":"Review the details on the page to ensure correctness. Click \"Create\" to generate a new index and IAM role with specified access settings and provisioning edition. \u26a0\ufe0f Propagating IAM Role and creating the Index can take up to 30 minutes.","title":"Review and Create"},{"location":"additional_info/aws_LLM/kendra_keys/#kendra-index-id","text":"Under the \"Index Setting\" section, copy the unique \" Index ID \" to use as the \"Kendra Index ID\" in the Corporate Knowledge Base Details section of NeuralSeek's Configure tab.","title":"Kendra Index ID"},{"location":"additional_info/aws_LLM/kendra_keys/#create-user","text":"Navigate to IAM in the AWS Console. (a) Click \"Users\" on the left sidebar menu. (b) Click \"Create a User\". (c) Add a user name. For this example, \" learninglab-testgroup \". Click \"Next\". Click \"Create Group.\" (e) Add a user group name. For this example, \" learninglab-testgroup \". (f) Select a policy name based on the best use case. For the purpose of this lab, select the \" AmazonKendraReadOnlyAccess \" policy name. (g) Click \"Create user group\", then click \"Next.\" Review the details, then click \"Create User\" to create the user.","title":"Create User"},{"location":"additional_info/aws_LLM/kendra_keys/#create-access-key","text":"Navigate to the \"Security Credentials\" tab under the selected user after verifying that the user is added to the correct group. (a) In the \"Access keys\" section, click \"Create access key.\" (b) Select the appropriate \"Use case.\" For this example, select \" Application running outside AWS \". (c) Click \"Next\". Click \"Create access key\" to successfully create an access key.","title":"Create Access Key"},{"location":"additional_info/aws_LLM/kendra_keys/#aws-role-access-keys","text":"\u26a0\ufe0f Disclaimer: the secret access key will be accessible only once. It is important to copy the secret access key prior to proceeding. On the \"Retrieve access keys\" page, copy the unique \" Access key \" to use as the \"AWS Role Access Key\" in the Corporate Knowledge Base Details section of NeuralSeek's Configure tab. On the same page, copy the unique \" Secret access key \" to use as the \"AWS Role Secret Access Key\" in the Corporate Knowledge Base Details section of NeuralSeek's Configure tab. Click \"Done\" to successfully add the essential AWS Access Key information into NeuralSeek when configuring the AWS Kendra Index KnowledgeBase.","title":"AWS Role Access Keys"},{"location":"additional_info/ibm_LLM/ibm_module1-7/","text":"Connect a Large Language Model (LLM) with NeuralSeek Enhance your NeuralSeek experience by following these instructions to seamlessly add at least one LLM (Large Language Model) to optimize its functionalities. If you add more than one, NeuralSeek will balance them for functions that can use multiple LLMs. If an LLM can't handle certain features, those features won't be available. If you don't add an LLM for a function, that part of NeuralSeek won't work. \u26a0 In order to configure a LLM, make sure that you have subscribed to the Bring Your Own LLM (BYOLLM) plan. All other plans will default to NeuralSeek\u2019s curated LLM, and this option will not be available. Remember, it is the responsibility of each participant to understand and manage the associated costs related to the use of NeuralSeek and any other integrated services within their IBM Cloud environment. Add an LLM Navigate to the NeuralSeek user interface. In the \"Home\" tab, follow the steps to connect to your LLM. \u26a0\ufe0f You must add at least one LLM. (a) Click \"Add an LLM\". Platform and LLM Selection For IBM users, it is recommended to connect to the watsonx platform, and the Llama-2-chat 70B LLM selection. (a) Click the drop-down menu to select the LLM platform. For this example, select \" watsonx \". (b) Click the drop-down menu to select the LLM. For this example, select \" Llama-2-chat 70B \". (c) Click \"Add\" to add the LLM. LLM Functions Location of watsonx IAM API Key, Endpoint URL, and Project ID information can be found on your IBM Cloud account within the active instance found in the Resource List. Enter the watsonx IAM API Key. Enter the watsonx Endpoint URL. Enter the watsonx Project ID. Enable available LLM languages. NeuralSeek will default to enable all 56 available languages. Select desired LLM functions. NeuralSeek will default to select all available functions. For the purpose of this lab, select the following: PII Detection, Conversation Generation, Entity Extraction, Categorization, Example Generation, Intent Creation, Translate, Fallback Sentiment, and Explore . Test the LLM Click \"Test\" to test the LLM. A Large Language Model is now connected to NeuralSeek. \u26a0\ufe0f LLM's can vary in their capabilities and performances. Some LLM can take up to 30 seconds and longer to generate a full response. Use caution when using in conjunction with a virtual agent platform that imposes a strict timeout.","title":"IBM - Connect LLM"},{"location":"additional_info/ibm_LLM/ibm_module1-7/#connect-a-large-language-model-llm-with-neuralseek","text":"Enhance your NeuralSeek experience by following these instructions to seamlessly add at least one LLM (Large Language Model) to optimize its functionalities. If you add more than one, NeuralSeek will balance them for functions that can use multiple LLMs. If an LLM can't handle certain features, those features won't be available. If you don't add an LLM for a function, that part of NeuralSeek won't work. \u26a0 In order to configure a LLM, make sure that you have subscribed to the Bring Your Own LLM (BYOLLM) plan. All other plans will default to NeuralSeek\u2019s curated LLM, and this option will not be available. Remember, it is the responsibility of each participant to understand and manage the associated costs related to the use of NeuralSeek and any other integrated services within their IBM Cloud environment.","title":"Connect a Large Language Model (LLM) with NeuralSeek"},{"location":"additional_info/ibm_LLM/ibm_module1-7/#add-an-llm","text":"Navigate to the NeuralSeek user interface. In the \"Home\" tab, follow the steps to connect to your LLM. \u26a0\ufe0f You must add at least one LLM. (a) Click \"Add an LLM\".","title":"Add an LLM"},{"location":"additional_info/ibm_LLM/ibm_module1-7/#platform-and-llm-selection","text":"For IBM users, it is recommended to connect to the watsonx platform, and the Llama-2-chat 70B LLM selection. (a) Click the drop-down menu to select the LLM platform. For this example, select \" watsonx \". (b) Click the drop-down menu to select the LLM. For this example, select \" Llama-2-chat 70B \". (c) Click \"Add\" to add the LLM.","title":"Platform and LLM Selection"},{"location":"additional_info/ibm_LLM/ibm_module1-7/#llm-functions","text":"Location of watsonx IAM API Key, Endpoint URL, and Project ID information can be found on your IBM Cloud account within the active instance found in the Resource List. Enter the watsonx IAM API Key. Enter the watsonx Endpoint URL. Enter the watsonx Project ID. Enable available LLM languages. NeuralSeek will default to enable all 56 available languages. Select desired LLM functions. NeuralSeek will default to select all available functions. For the purpose of this lab, select the following: PII Detection, Conversation Generation, Entity Extraction, Categorization, Example Generation, Intent Creation, Translate, Fallback Sentiment, and Explore .","title":"LLM Functions"},{"location":"additional_info/ibm_LLM/ibm_module1-7/#test-the-llm","text":"Click \"Test\" to test the LLM. A Large Language Model is now connected to NeuralSeek. \u26a0\ufe0f LLM's can vary in their capabilities and performances. Some LLM can take up to 30 seconds and longer to generate a full response. Use caution when using in conjunction with a virtual agent platform that imposes a strict timeout.","title":"Test the LLM"},{"location":"closing/closing/","text":"After the lab is finished, it is important to make sure that the subscriptions and instances would be deleted so that any unexpected usage cost does not incur. Failing to do so may result in unnecessary billing to occur, so it is highly recommended that you would clean up the created resources after you are finished. Removing AWS Components In order to remove the subscribed NeuralSeek, please follow the below steps. Visit the AWS Marketplace subscriptions page. Click the \"Manage\" button under the subscription. In the Agreement section, click Actions and select Cancel subscription Read and enter confirm to the input field, and click Yes, cancel subscription . Check that the NeuralSeek subscription is no longer visible in the manage subscriptions page. Visit the Amazon Lex console . Select the bot \"TestBot\". Click \"Action\", and select \"Delete\". Confirm successful deletion. Visit the Functions page. Select the function \"learning-lab\". Click \"Action\", and select \"Delete\". Confirm successful deletion. Removing IBM Components In order to remove the NeuralSeek instance, please follow the below steps: Visit the IBM cloud resources page. Search and locate the NeuralSeek instance that you have created during the lab. Click the instance name. Select Actions and select Delete service Click OK Check that the NeuralSeek instance is no longer visible in the resources page. Search and locate the Watson Assistant instance that you have created during the lab. Click the instance name. Select Actions and select Delete service Click OK Check that the Watson Assistant instance is no longer visible in the resources page.","title":"Closing Steps"},{"location":"closing/closing/#removing-aws-components","text":"In order to remove the subscribed NeuralSeek, please follow the below steps. Visit the AWS Marketplace subscriptions page. Click the \"Manage\" button under the subscription. In the Agreement section, click Actions and select Cancel subscription Read and enter confirm to the input field, and click Yes, cancel subscription . Check that the NeuralSeek subscription is no longer visible in the manage subscriptions page. Visit the Amazon Lex console . Select the bot \"TestBot\". Click \"Action\", and select \"Delete\". Confirm successful deletion. Visit the Functions page. Select the function \"learning-lab\". Click \"Action\", and select \"Delete\". Confirm successful deletion.","title":"Removing AWS Components"},{"location":"closing/closing/#removing-ibm-components","text":"In order to remove the NeuralSeek instance, please follow the below steps: Visit the IBM cloud resources page. Search and locate the NeuralSeek instance that you have created during the lab. Click the instance name. Select Actions and select Delete service Click OK Check that the NeuralSeek instance is no longer visible in the resources page. Search and locate the Watson Assistant instance that you have created during the lab. Click the instance name. Select Actions and select Delete service Click OK Check that the Watson Assistant instance is no longer visible in the resources page.","title":"Removing IBM Components"},{"location":"module1/module1/","text":"Module 1: Configuration and Integration The purpose of Module 1: Configuration and Integration is to authenticate and connect NeuralSeek with a KnowledgeBase and a Virtual Agent. Level: Entry Time: 20 minutes No Code Required Setting up with IBM Cloud We recommended connecting NeuralSeek with IBM Watson Discovery and IBM watsonx Assistant . Click here to get started: Module 1 - IBM . Setting up with AWS Marketplace We recommended connecting NeuralSeek with AWS Kendra and AWS Lex . Click here to get started: Module 1 - AWS .","title":"Overview"},{"location":"module1/module1/#module-1-configuration-and-integration","text":"The purpose of Module 1: Configuration and Integration is to authenticate and connect NeuralSeek with a KnowledgeBase and a Virtual Agent. Level: Entry Time: 20 minutes No Code Required","title":"Module 1: Configuration and Integration"},{"location":"module1/module1/#setting-up-with-ibm-cloud","text":"We recommended connecting NeuralSeek with IBM Watson Discovery and IBM watsonx Assistant . Click here to get started: Module 1 - IBM .","title":"Setting up with IBM Cloud"},{"location":"module1/module1/#setting-up-with-aws-marketplace","text":"We recommended connecting NeuralSeek with AWS Kendra and AWS Lex . Click here to get started: Module 1 - AWS .","title":"Setting up with AWS Marketplace"},{"location":"module1/module1_aws/module1_aws/","text":"Overview The goal of Module 1 - AWS of the Learning Lab is to provide users with the essential steps on how to effectively incorporate NeuralSeek's advanced conversational capabilities into a current AWS environment. By the end of this module, users will have a solid understanding of the steps involved in provisioning NeuralSeek, integrating it seamlessly with an AWS Kendra instance, and setting up a seamless integration with an AWS Lex virtual agent. By leveraging the combined power of NeuralSeek and AWS's pioneering technology, prepare to enhance your technical expertise and optimize customer engagement strategies. Disclaimer Before participating in this Learning Lab, it is essential that users come prepared with the necessary resources to fully engage in the practical exercises. If following the lab independently, we recommend having an active instance of an: Active NeuralSeek subscription : we recommend the Pay-per-Answer plan. If BYOLLM plan is selected, we recommend the Amazon Bedrock Large Language Model (LLM)\" Claude 2. \". KnowledgeBase : we recommend the AWS KnowledgeBase \" Kendra Index. \". Virtual Agent : we recommend the AWS Virtual Agent \" LexV2 Lambda. \" \u26a0\ufe0f Please be aware that any purchases or subscriptions related to the aforementioned tools must be made independently by the users. Additionally, to access NeuralSeek functionalities within the lab, users are required to have an active subscription to NeuralSeek on the AWS Marketplace. It is the responsibility of each participant to understand and manage the associated costs related to the use of NeuralSeek and any other integrated services within their AWS environment. Kindly ensure that all necessary resources are set up and accessible prior to beginning the Learning Lab for a seamless and enriching experience.","title":"Introduction"},{"location":"module1/module1_aws/module1_aws/#overview","text":"The goal of Module 1 - AWS of the Learning Lab is to provide users with the essential steps on how to effectively incorporate NeuralSeek's advanced conversational capabilities into a current AWS environment. By the end of this module, users will have a solid understanding of the steps involved in provisioning NeuralSeek, integrating it seamlessly with an AWS Kendra instance, and setting up a seamless integration with an AWS Lex virtual agent. By leveraging the combined power of NeuralSeek and AWS's pioneering technology, prepare to enhance your technical expertise and optimize customer engagement strategies.","title":"Overview"},{"location":"module1/module1_aws/module1_aws/#disclaimer","text":"Before participating in this Learning Lab, it is essential that users come prepared with the necessary resources to fully engage in the practical exercises. If following the lab independently, we recommend having an active instance of an: Active NeuralSeek subscription : we recommend the Pay-per-Answer plan. If BYOLLM plan is selected, we recommend the Amazon Bedrock Large Language Model (LLM)\" Claude 2. \". KnowledgeBase : we recommend the AWS KnowledgeBase \" Kendra Index. \". Virtual Agent : we recommend the AWS Virtual Agent \" LexV2 Lambda. \" \u26a0\ufe0f Please be aware that any purchases or subscriptions related to the aforementioned tools must be made independently by the users. Additionally, to access NeuralSeek functionalities within the lab, users are required to have an active subscription to NeuralSeek on the AWS Marketplace. It is the responsibility of each participant to understand and manage the associated costs related to the use of NeuralSeek and any other integrated services within their AWS environment. Kindly ensure that all necessary resources are set up and accessible prior to beginning the Learning Lab for a seamless and enriching experience.","title":"Disclaimer"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/","text":"Module 1.1 Log in Log in to the AWS Console Marketplace page . Click the yellow Manage subscriptions button. Discover products \u26a0\ufe0f If you already have subscribed to NeuralSeek, you do not have to do these steps. Please move to the Manage subscriptions section and continue. On the left side menu, click Discover products . In the Search AWS Marketplace products enter NeuralSeek and press enter. You will see two products in the search result: Selecting the product If you do not have access to your own large language model (LLM), you may choose the first one which is NeuralSeek , which does provide our curated LLM included in it. If you do have your own LLM, and thus have the necessary keys and region, (role access key, secret access key, and region) you can choose NeuralSeek - Bring Your Own Large Language Model . \u26a0\ufe0f Please note that these NeuralSeek subscriptions, when created, will incur billing and cost as they are used. Purchasing After you select a product from the list, click the View purchase options button at the top right. Review the offer, and pricing information. When ready click the Subscribe button under Purchase . Manage Subscriptions Go back to your Manage subscriptions page. You may either have NeuralSeek or NeuralSeek - Bring Your Own Large Language Model depending on what you chose to subscribe for the lab. Set up Product Click Set up Product in the bottom right corner to enter the product setup page. Set up Account Click Set up your account in the top right corner to enter the NeuralSeek instance control page. User Interface NeuralSeek's instance control page should be initially empty. Here, we need to: 1. Create a user for accessing NeuralSeek instance 2. Create an instance of NeuralSeek 3. Add created user to the created NeuralSeek instance Create a User You will need to have a user account to be able to connect to NeuralSeek. (a) Enter email address into Add User (Email) box. (b) Click on the plus icon to add a user. Generate Password (a) Newly created user\u2019s email will populate below. (b) A new password will be generated. Passwords can be changed later using the password reset functionality. Create an Instance Generating an instance at this stage will not initiate any server activity. Creating an instance merely establishes a unique identifier within the database, enabling authentication and access to the system. (a) Select desired location in the Create Instance box. For this lab, we recommend US-West-2 . (b) Click the plus icon to create an instance. Update Instance Name The newly created instance will populate below, and an instance ID will be generated. (a) Click the writing tool icon . (b) Enter desired instance name into text box. For the purpose of this lab, we recommend learning-lab-test . (c) Click the writing tool icon to save changes. (d) Updated instance name will populate. Connect To allow the user to connect to the instance: (a) Click Configure User Access to Instances plus icon . (b) Click the plus icon . (c) User is now able to connect to the instance. Instance Link Click the instance link learning-lab-test in the list of instances. Log In Fill out the necessary information below to log in to NeuralSeek. (a) Enter user email address. (b) Enter user password generated from the Create a User section in Module 1.2 . If desired, you are able to reset the password using the Forgot password? link. Continue Click Continue to be directed to the NeuralSeek user interface page. An active user and instance of NeuralSeek is now set up within the AWS console and ready to be connected to a KnowledgeBase. \u26a0\ufe0f For 'NeuralSeek - Bring Your Own Large Language Model' lab participants: If you have selected NeuralSeek - Bring Your Own Large Language Model and wish to use your own LLM for the lab, please refer to the Additional Information - LLM section of the lab guide for steps to configure your LLM on NeuralSeek.","title":"1.1 - Launch NeuralSeek"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#module-11","text":"","title":"Module 1.1"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#log-in","text":"Log in to the AWS Console Marketplace page . Click the yellow Manage subscriptions button.","title":"Log in"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#discover-products","text":"\u26a0\ufe0f If you already have subscribed to NeuralSeek, you do not have to do these steps. Please move to the Manage subscriptions section and continue. On the left side menu, click Discover products . In the Search AWS Marketplace products enter NeuralSeek and press enter. You will see two products in the search result:","title":"Discover products"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#selecting-the-product","text":"If you do not have access to your own large language model (LLM), you may choose the first one which is NeuralSeek , which does provide our curated LLM included in it. If you do have your own LLM, and thus have the necessary keys and region, (role access key, secret access key, and region) you can choose NeuralSeek - Bring Your Own Large Language Model . \u26a0\ufe0f Please note that these NeuralSeek subscriptions, when created, will incur billing and cost as they are used.","title":"Selecting the product"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#purchasing","text":"After you select a product from the list, click the View purchase options button at the top right. Review the offer, and pricing information. When ready click the Subscribe button under Purchase .","title":"Purchasing"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#manage-subscriptions","text":"Go back to your Manage subscriptions page. You may either have NeuralSeek or NeuralSeek - Bring Your Own Large Language Model depending on what you chose to subscribe for the lab.","title":"Manage Subscriptions"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#set-up-product","text":"Click Set up Product in the bottom right corner to enter the product setup page.","title":"Set up Product"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#set-up-account","text":"Click Set up your account in the top right corner to enter the NeuralSeek instance control page.","title":"Set up Account"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#user-interface","text":"NeuralSeek's instance control page should be initially empty. Here, we need to: 1. Create a user for accessing NeuralSeek instance 2. Create an instance of NeuralSeek 3. Add created user to the created NeuralSeek instance","title":"User Interface"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#create-a-user","text":"You will need to have a user account to be able to connect to NeuralSeek. (a) Enter email address into Add User (Email) box. (b) Click on the plus icon to add a user.","title":"Create a User"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#generate-password","text":"(a) Newly created user\u2019s email will populate below. (b) A new password will be generated. Passwords can be changed later using the password reset functionality.","title":"Generate Password"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#create-an-instance","text":"Generating an instance at this stage will not initiate any server activity. Creating an instance merely establishes a unique identifier within the database, enabling authentication and access to the system. (a) Select desired location in the Create Instance box. For this lab, we recommend US-West-2 . (b) Click the plus icon to create an instance.","title":"Create an Instance"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#update-instance-name","text":"The newly created instance will populate below, and an instance ID will be generated. (a) Click the writing tool icon . (b) Enter desired instance name into text box. For the purpose of this lab, we recommend learning-lab-test . (c) Click the writing tool icon to save changes. (d) Updated instance name will populate.","title":"Update Instance Name"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#connect","text":"To allow the user to connect to the instance: (a) Click Configure User Access to Instances plus icon . (b) Click the plus icon . (c) User is now able to connect to the instance.","title":"Connect"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#instance-link","text":"Click the instance link learning-lab-test in the list of instances.","title":"Instance Link"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#log-in_1","text":"Fill out the necessary information below to log in to NeuralSeek. (a) Enter user email address. (b) Enter user password generated from the Create a User section in Module 1.2 . If desired, you are able to reset the password using the Forgot password? link.","title":"Log In"},{"location":"module1/module1_aws/aws_module1-1/aws_module1-1/#continue","text":"Click Continue to be directed to the NeuralSeek user interface page. An active user and instance of NeuralSeek is now set up within the AWS console and ready to be connected to a KnowledgeBase. \u26a0\ufe0f For 'NeuralSeek - Bring Your Own Large Language Model' lab participants: If you have selected NeuralSeek - Bring Your Own Large Language Model and wish to use your own LLM for the lab, please refer to the Additional Information - LLM section of the lab guide for steps to configure your LLM on NeuralSeek.","title":"Continue"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/","text":"Module 1.2 Basics - Getting Started First, we need a short writeup about your company or organization, focusing on the use-case for this instance of NeuralSeek. (a) Add a brief company or organization description. (b) Select \"Output Language\" from the drop down menu. In this example, select \" English \". It's best to match the language of your KnowledgeBase and questions, but NeuralSeek is able to translate between many languages. (c) Select preferred use of NeuralSeek instance. Will this instance of NeuralSeek be used internally within your organization, or is it external - customer facing? We'll use this info to pre-tune some safety parameters for you. In this example, select \" Internal \". Click \"Next\" to save a unique description, language and use-case choice. Data - Connect to your KnowledgeBase (a) Select desired KnowledgeBase from the drop-down menu. For the purpose of this lab, we recommend the AWS KnowledgeBase \" Kendra .\" (b) Select desired language. For the purpose of this lab, click \" English .\" Add KnowledgeBase Information User is responsible for providing selected KnowledgeBase details information. Since it takes time to set these up for yourself, we are going to be using the one that is already prepared for the learning lab, with read-only access. The actual values below will be provided during the course of this lab by the lab instructor. \u26a0\ufe0f To understand how to create and locate the AWS access keys, refer to the Additional Information - Access Keys section of the lab guide. Please enter the following: (a) Add \"Kendra Index ID\". (b) Add \"AWS Role Access Key\". (c) Add \"AWS Region\". (d) Add \"AWS Role Secret Access Key\". Click the \"Test\" button to test the connection. Then, click \"Next\" to save KnowledgeBase configuration. NeuralSeek is now set up with a KnowledgeBase, in this case: Kendra Index , and ready to seek. \u26a0\ufe0f For creating your own Kendra index to do the lab With the interest of time, the lab will use an already built-in Kendra index that is pre-filled with the data. That is because of the fact that creating Kendra index and populating the data would take from 40 minutes to even over an hour to complete. However, in case you are interested to later perform the lab using your own Kendra index and keys, you can follow the below instruction. \ud83d\udd17 Setting up AWS Kendra Index and Access Keys . Organize - Outputs and Categories Categorization Categorize your intents for easier reporting and management. If following the live lab, skip this step! (a) Click the light bulb icon to add a new row. (b) Enter in a unique category name, a corresponding URL, and a detailed description of the category with intents that do not match any other category. Virtual Agent Framework (a) Select \"Virtual Agent Type\" from the drop down menu. In this example, select \" AWS Lex V2 \". (b) Select preferred choice of enabling or disabling embedding links into returned responses. In this example, select \" Disable \". Click \"Next\" to save reported categories andthe selected Virtual Agent framework. Tune - Tune for your Data Let's tune NeuralSeek for your data. (a) Select the preferred option for \"Which of these looks more like your data?\". For this example, select \" Important phrases are surrounded by many lines of text that explain them. \". The option \" Important phrases are surrounded by many lines of text that explain them \", describes data with more elaborate explanations with more extensive passages of text for a better understanding. The option \" Important phrases are surrounded by only a line or two of relevant information \", describes data with concise coverage of key phrases with just a line or two of necessary context. (b) Select the preferred option that best describes your data requirements. For this example, select \" I want to give lots of information to the LLM, and give it leeway to decide the answer. \" (c) Select the preferred option that best describes your data currency. For this example, select \" All of my documents are current and relevant. \". The option \" All of my documents are current and relevant \", describes data that is up-to-date. The option \" I have lots of old documents or blog posts, some with conflicting information. I need NeuralSeek to help with date prioritization \", describes data that may have conflicting or irrelevant details across different sources or documents. Click \"Next\" to save reported tuning configurations. Question and Answer As questions are answered by NeuralSeek, we can automatically build out and maintain portions of your Virtual Agent. Use the buttons below to quickly generate Q&A content to bootstrap and test your Virtual Agent. Auto-Generate Questions will query the knowledgebase, ask NeuralSeek to generate insights and output a variety of test questions based on your corporate content. Click \"Submit\" to have NeuralSeek generate answers. Manually Input Questions will provide a blank test box for you to enter questions, one per line, based on your corporate content. Click \"Submit\" to have NeuralSeek generate answers. Upload Test Questions will provide a link to your local file explorer to upload a CSV file of test questions. The questions will be run through the Seek endpoint in parallel and scored. Please use the provided downloadable .csv file as a template for your questions. Input files must retain these column titles at a minimum, but you may add additional payload columns. Click \"Submit\" to have NeuralSeek generate answers. NeuralSeek is now ready to answer! Ready NeuralSeek is ready to seek. NeuralSeek is now set up and ready to use.","title":"1.2 - Set Up NeuralSeek"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/#module-12","text":"","title":"Module 1.2"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/#basics-getting-started","text":"First, we need a short writeup about your company or organization, focusing on the use-case for this instance of NeuralSeek. (a) Add a brief company or organization description. (b) Select \"Output Language\" from the drop down menu. In this example, select \" English \". It's best to match the language of your KnowledgeBase and questions, but NeuralSeek is able to translate between many languages. (c) Select preferred use of NeuralSeek instance. Will this instance of NeuralSeek be used internally within your organization, or is it external - customer facing? We'll use this info to pre-tune some safety parameters for you. In this example, select \" Internal \". Click \"Next\" to save a unique description, language and use-case choice.","title":"Basics - Getting Started"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/#data-connect-to-your-knowledgebase","text":"(a) Select desired KnowledgeBase from the drop-down menu. For the purpose of this lab, we recommend the AWS KnowledgeBase \" Kendra .\" (b) Select desired language. For the purpose of this lab, click \" English .\"","title":"Data - Connect to your KnowledgeBase"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/#add-knowledgebase-information","text":"User is responsible for providing selected KnowledgeBase details information. Since it takes time to set these up for yourself, we are going to be using the one that is already prepared for the learning lab, with read-only access. The actual values below will be provided during the course of this lab by the lab instructor. \u26a0\ufe0f To understand how to create and locate the AWS access keys, refer to the Additional Information - Access Keys section of the lab guide. Please enter the following: (a) Add \"Kendra Index ID\". (b) Add \"AWS Role Access Key\". (c) Add \"AWS Region\". (d) Add \"AWS Role Secret Access Key\". Click the \"Test\" button to test the connection. Then, click \"Next\" to save KnowledgeBase configuration. NeuralSeek is now set up with a KnowledgeBase, in this case: Kendra Index , and ready to seek.","title":"Add KnowledgeBase Information"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/#for-creating-your-own-kendra-index-to-do-the-lab","text":"With the interest of time, the lab will use an already built-in Kendra index that is pre-filled with the data. That is because of the fact that creating Kendra index and populating the data would take from 40 minutes to even over an hour to complete. However, in case you are interested to later perform the lab using your own Kendra index and keys, you can follow the below instruction. \ud83d\udd17 Setting up AWS Kendra Index and Access Keys .","title":"\u26a0\ufe0f For creating your own Kendra index to do the lab"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/#organize-outputs-and-categories","text":"","title":"Organize - Outputs and Categories"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/#categorization","text":"Categorize your intents for easier reporting and management. If following the live lab, skip this step! (a) Click the light bulb icon to add a new row. (b) Enter in a unique category name, a corresponding URL, and a detailed description of the category with intents that do not match any other category.","title":"Categorization"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/#virtual-agent-framework","text":"(a) Select \"Virtual Agent Type\" from the drop down menu. In this example, select \" AWS Lex V2 \". (b) Select preferred choice of enabling or disabling embedding links into returned responses. In this example, select \" Disable \". Click \"Next\" to save reported categories andthe selected Virtual Agent framework.","title":"Virtual Agent Framework"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/#tune-tune-for-your-data","text":"Let's tune NeuralSeek for your data. (a) Select the preferred option for \"Which of these looks more like your data?\". For this example, select \" Important phrases are surrounded by many lines of text that explain them. \". The option \" Important phrases are surrounded by many lines of text that explain them \", describes data with more elaborate explanations with more extensive passages of text for a better understanding. The option \" Important phrases are surrounded by only a line or two of relevant information \", describes data with concise coverage of key phrases with just a line or two of necessary context. (b) Select the preferred option that best describes your data requirements. For this example, select \" I want to give lots of information to the LLM, and give it leeway to decide the answer. \" (c) Select the preferred option that best describes your data currency. For this example, select \" All of my documents are current and relevant. \". The option \" All of my documents are current and relevant \", describes data that is up-to-date. The option \" I have lots of old documents or blog posts, some with conflicting information. I need NeuralSeek to help with date prioritization \", describes data that may have conflicting or irrelevant details across different sources or documents. Click \"Next\" to save reported tuning configurations.","title":"Tune - Tune for your Data"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/#question-and-answer","text":"As questions are answered by NeuralSeek, we can automatically build out and maintain portions of your Virtual Agent. Use the buttons below to quickly generate Q&A content to bootstrap and test your Virtual Agent. Auto-Generate Questions will query the knowledgebase, ask NeuralSeek to generate insights and output a variety of test questions based on your corporate content. Click \"Submit\" to have NeuralSeek generate answers. Manually Input Questions will provide a blank test box for you to enter questions, one per line, based on your corporate content. Click \"Submit\" to have NeuralSeek generate answers. Upload Test Questions will provide a link to your local file explorer to upload a CSV file of test questions. The questions will be run through the Seek endpoint in parallel and scored. Please use the provided downloadable .csv file as a template for your questions. Input files must retain these column titles at a minimum, but you may add additional payload columns. Click \"Submit\" to have NeuralSeek generate answers. NeuralSeek is now ready to answer!","title":"Question and Answer"},{"location":"module1/module1_aws/aws_module1-2/aws_module1-2/#ready","text":"NeuralSeek is ready to seek. NeuralSeek is now set up and ready to use.","title":"Ready"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/","text":"Module 1.3 Integrate Navigate to the \u201cIntegrate\u201d tab in NeuralSeek. Select Virtual Agent Select the preferred choice of virtual agent on the left side menu. For this lab, we recommend \" LexV2 Lambda \". Download File Download the Lambda Archive .zip file to your local storage. Create a Function Click the link to open the Functions page on the AWS Lambda console to create a function from scratch. - (a) Select \"Create Function\". - (b) Add a \u201cFunction Name\u201d. For this lab, we recommend \u201clearning-lab\u201d. - (c) Click \u201cCreate Function\u201d. Upload the downloaded .zip File Navigate to the Code Source pane in the AWS Lambda Function console. - (a) Click \u201cUpload from\u201d. Click \u201c.zip file\u201d. - (b) Click \u201cUpload\u201d to select your Lambda Archive .zip file you downloaded. - (c) Click \u201cSave\u201d. Edit the Code Block On the NeuralSeek \"Integrate\" page, copy the provided API key and Instance URL mentioned in the NeuralSeek's integration page. Navigate to the Code Source pane in the AWS Lambda Function console. - (a) Click on the \u201cindex.mjs\u201d file tab. - (b) Enter the copied API key and Instance URL into the code block. - (c) Within the \"messages\" array, delete the section containing the contentType: \"CustomPayload\" from the code block. The \"Deploy\" button will enable. Click \"Deploy\" to successfully update and deploy the function. Update Timeout Setting Navigate to the \"Configuration\" tab in AWS Lambda Function Console. (a) In the \"General Configuration\" pane, click \"Edit\". (b) Update under \u201cTimeout\u201d: set min to be \u201c1\u201d and sec to be \u201c0\u201d. This will ensure the lambda function will not time out for 1 minute. (c) Click \"Save\". Create a Lex Bot Open the Amazon Lex console . click \"Create bot\" under the Bots section. In the creation method, select \"Create a blank bot\". Name the bot \"TestBot\". Select \"Create a role with basic Amazon Lex permissions\" in IAM Permissions. Select \"No\" in Children's Online Privacy Protection Act (COPPA). Click \"Next\". Click \"Done\". In the Sample utterances section, add an utterance. It can be anything (e.g. Hello). In the Initial response section, add any response that may be suitable. (e.g. Welcome to the test bot). Click \"Save intent\" to save a default intent without adding anything. Selecting Alias Open the Amazon Lex console . Select the \"TestBot\" from the list of the Bots. - (a) On the left side bar menu, under \u201cDeployment\u201d, click \u201cAliases\u201d. - (b) From the list of alias names, choose the alias name that you want to use. Select \" TestBotAlias \". Select Language Under the chosen Alias, \" TestBotAlias \" within the Amazon Lex console : (a) From the list of supported languages, click the language that the Lambda function is used for. For this lab, we recommend \u201c English \u201d. Optional Lambda Function Connection (a) Under \"Source\", click the name of the alias of the Lambda function to use. For this lab, we recommend \" learning-lab \u201d. (b) Under \"Lambda function version or alias\", the option \" $LATEST \" will populate. (c) Click \u201cSave\u201d. Fallback Activities The default FallbackIntent allows for the Lambda function to be called when it is detected. The idea is that Lex would invoke NeuralSeek to answer whenever there is no matching intent found. To activate this, navigate to Amazon Lex console . (a) Click \u201cTestBot\u201d (b) Click \u201cIntents\u201d under \u201cEnglish (US)\u201d on the left sidebar menu. (c) Click on the \u201cFallbackIntent\u201d link. Under the \"Fulfillment\" section, click the \"Activate\" icon to turn on. (a) Click \"Advanced Options\" (b) Select the \u201cUse a Lambda Function for Fulfillment\u201d option. (c) Click \"Update Options.\" Click \"Save Intent.\" Build the chatbot and test the FallbackIntent routine with a question. (a) Click \u201cBuild.\u201d This step may take a few moments. (b) Click \u201cTest.\u201d The Amazon Lex chatbot will be generated. Prompt the chatbot with a question. For the purpose of this lab, we used \u201c What is NeuralSeek? \u201d Notice the answer and the detailed information about the answer is returned to the chat bot. The AWS LexV2 Lambda Virtual Agent is now set up, integrated with NeuralSeek, tested and ready for use.","title":"1.3 - Integrate Virtual Agent"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#module-13","text":"","title":"Module 1.3"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#integrate","text":"Navigate to the \u201cIntegrate\u201d tab in NeuralSeek.","title":"Integrate"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#select-virtual-agent","text":"Select the preferred choice of virtual agent on the left side menu. For this lab, we recommend \" LexV2 Lambda \".","title":"Select Virtual Agent"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#download-file","text":"Download the Lambda Archive .zip file to your local storage.","title":"Download File"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#create-a-function","text":"Click the link to open the Functions page on the AWS Lambda console to create a function from scratch. - (a) Select \"Create Function\". - (b) Add a \u201cFunction Name\u201d. For this lab, we recommend \u201clearning-lab\u201d. - (c) Click \u201cCreate Function\u201d.","title":"Create a Function"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#upload-the-downloaded-zip-file","text":"Navigate to the Code Source pane in the AWS Lambda Function console. - (a) Click \u201cUpload from\u201d. Click \u201c.zip file\u201d. - (b) Click \u201cUpload\u201d to select your Lambda Archive .zip file you downloaded. - (c) Click \u201cSave\u201d.","title":"Upload the downloaded .zip File"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#edit-the-code-block","text":"On the NeuralSeek \"Integrate\" page, copy the provided API key and Instance URL mentioned in the NeuralSeek's integration page. Navigate to the Code Source pane in the AWS Lambda Function console. - (a) Click on the \u201cindex.mjs\u201d file tab. - (b) Enter the copied API key and Instance URL into the code block. - (c) Within the \"messages\" array, delete the section containing the contentType: \"CustomPayload\" from the code block. The \"Deploy\" button will enable. Click \"Deploy\" to successfully update and deploy the function.","title":"Edit the Code Block"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#update-timeout-setting","text":"Navigate to the \"Configuration\" tab in AWS Lambda Function Console. (a) In the \"General Configuration\" pane, click \"Edit\". (b) Update under \u201cTimeout\u201d: set min to be \u201c1\u201d and sec to be \u201c0\u201d. This will ensure the lambda function will not time out for 1 minute. (c) Click \"Save\".","title":"Update Timeout Setting"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#create-a-lex-bot","text":"Open the Amazon Lex console . click \"Create bot\" under the Bots section. In the creation method, select \"Create a blank bot\". Name the bot \"TestBot\". Select \"Create a role with basic Amazon Lex permissions\" in IAM Permissions. Select \"No\" in Children's Online Privacy Protection Act (COPPA). Click \"Next\". Click \"Done\". In the Sample utterances section, add an utterance. It can be anything (e.g. Hello). In the Initial response section, add any response that may be suitable. (e.g. Welcome to the test bot). Click \"Save intent\" to save a default intent without adding anything.","title":"Create a Lex Bot"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#selecting-alias","text":"Open the Amazon Lex console . Select the \"TestBot\" from the list of the Bots. - (a) On the left side bar menu, under \u201cDeployment\u201d, click \u201cAliases\u201d. - (b) From the list of alias names, choose the alias name that you want to use. Select \" TestBotAlias \".","title":"Selecting Alias"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#select-language","text":"Under the chosen Alias, \" TestBotAlias \" within the Amazon Lex console : (a) From the list of supported languages, click the language that the Lambda function is used for. For this lab, we recommend \u201c English \u201d.","title":"Select Language"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#optional-lambda-function-connection","text":"(a) Under \"Source\", click the name of the alias of the Lambda function to use. For this lab, we recommend \" learning-lab \u201d. (b) Under \"Lambda function version or alias\", the option \" $LATEST \" will populate. (c) Click \u201cSave\u201d.","title":"Optional Lambda Function Connection"},{"location":"module1/module1_aws/aws_module1-3/aws_module1-3/#fallback-activities","text":"The default FallbackIntent allows for the Lambda function to be called when it is detected. The idea is that Lex would invoke NeuralSeek to answer whenever there is no matching intent found. To activate this, navigate to Amazon Lex console . (a) Click \u201cTestBot\u201d (b) Click \u201cIntents\u201d under \u201cEnglish (US)\u201d on the left sidebar menu. (c) Click on the \u201cFallbackIntent\u201d link. Under the \"Fulfillment\" section, click the \"Activate\" icon to turn on. (a) Click \"Advanced Options\" (b) Select the \u201cUse a Lambda Function for Fulfillment\u201d option. (c) Click \"Update Options.\" Click \"Save Intent.\" Build the chatbot and test the FallbackIntent routine with a question. (a) Click \u201cBuild.\u201d This step may take a few moments. (b) Click \u201cTest.\u201d The Amazon Lex chatbot will be generated. Prompt the chatbot with a question. For the purpose of this lab, we used \u201c What is NeuralSeek? \u201d Notice the answer and the detailed information about the answer is returned to the chat bot. The AWS LexV2 Lambda Virtual Agent is now set up, integrated with NeuralSeek, tested and ready for use.","title":"Fallback Activities"},{"location":"module1/module1_ibm/module1_ibm/","text":"Overview The goal of Module 1 - IBM of the Learning Lab is to provide users with the essential steps on how to effectively incorporate NeuralSeek's advanced conversational capabilities into a current IBM system. By the end of this module, users will have a solid understanding of the steps involved in provisioning NeuralSeek, integrating it seamlessly with an IBM Watson Discovery instance, and setting up a seamless integration with an IBM watsonx Assistant virtual agent. By leveraging the combined power of NeuralSeek and IBM's pioneering technology, prepare to enhance your technical expertise and optimize customer engagement strategies. Disclaimer Before participating in this Learning Lab, it is essential that users come prepared with the necessary resources to fully engage in the practical exercises. We recommend having an active instance of an: Active NeuralSeek subscription . We recommend the Pay-per-Answer plan. If BYOLLM plan is selected, we recommend the watsonx platform Large Language Model (LLM) \" Llama-2-chat 70B \". KnowledgeBase , we recommend the IBM KnowledgeBase \" Watson Discovery \". Virtual Agent , we recommend the IBM Virtual Agent \" watsonx Assistant \". \u26a0\ufe0f Please be aware that any purchases or subscriptions related to the aforementioned tools must be made independently by the users. It is the responsibility of each participant to understand and manage the associated costs related to the use of NeuralSeek and any other integrated services within their IBM Cloud environment. Kindly ensure that all necessary resources are set up and accessible prior to beginning the Learning Lab for a seamless and enriching experience.","title":"Introduction"},{"location":"module1/module1_ibm/module1_ibm/#overview","text":"The goal of Module 1 - IBM of the Learning Lab is to provide users with the essential steps on how to effectively incorporate NeuralSeek's advanced conversational capabilities into a current IBM system. By the end of this module, users will have a solid understanding of the steps involved in provisioning NeuralSeek, integrating it seamlessly with an IBM Watson Discovery instance, and setting up a seamless integration with an IBM watsonx Assistant virtual agent. By leveraging the combined power of NeuralSeek and IBM's pioneering technology, prepare to enhance your technical expertise and optimize customer engagement strategies.","title":"Overview"},{"location":"module1/module1_ibm/module1_ibm/#disclaimer","text":"Before participating in this Learning Lab, it is essential that users come prepared with the necessary resources to fully engage in the practical exercises. We recommend having an active instance of an: Active NeuralSeek subscription . We recommend the Pay-per-Answer plan. If BYOLLM plan is selected, we recommend the watsonx platform Large Language Model (LLM) \" Llama-2-chat 70B \". KnowledgeBase , we recommend the IBM KnowledgeBase \" Watson Discovery \". Virtual Agent , we recommend the IBM Virtual Agent \" watsonx Assistant \". \u26a0\ufe0f Please be aware that any purchases or subscriptions related to the aforementioned tools must be made independently by the users. It is the responsibility of each participant to understand and manage the associated costs related to the use of NeuralSeek and any other integrated services within their IBM Cloud environment. Kindly ensure that all necessary resources are set up and accessible prior to beginning the Learning Lab for a seamless and enriching experience.","title":"Disclaimer"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/","text":"Module 1.1 Add NeuralSeek Log in to IBM Cloud . Search and select NeuralSeek from Catalog. (a) Select the Pay-per-answer plan type. (b) To agree to the third-party terms, in the bottom right, open and read the terms then check, \u201cI have read and agree to the following third-party terms\u201d. (c) To provision, click \u201cCreate\u201d. Please note that users are responsible for all incurred costs. Launch NeuralSeek Click \u201cLaunch NeuralSeek\u201d. Basics - Getting Started First, we need a short writeup about your company or organization, focusing on the use-case for this instance of NeuralSeek. (a) Add a brief company or organization description. (b) Select \"Output Language\" from the drop down menu. In this example, select \" English \". It's best to match the language of your KnowledgeBase and questions, but NeuralSeek is able to translate between many languages. (c) Select preferred use of NeuralSeek instance. Will this instance of NeuralSeek be used internally within your organization, or is it external - customer facing? We'll use this info to pre-tune some safety parameters for you. In this example, select \" Internal \". Data - Connect to your KnowledgeBase (a) Select KnowledgeBase. In this example \u201c Watson Discovery \u201d. (b) Select language. In this example \" English \". Add KnowledgeBase Information User is responsible for providing selected KnowledgeBase details information. Since it takes time to set these up for yourself, we are going to be using the one that is already prepared for the learning lab, with read-only access. The actual values below will be provided during the course of this lab by the lab instructor. Please enter the following: (a) Add \"Discovery Service URL\". (b) Add \"Discovery API Key\". (c) Add \"Discovery Project ID\". Click the \"Test\" button to test the connection. Then, click \"Next\" to save KnowledgeBase configuration. Organize - Outputs and Categories Categorization Categorize your intents for easier reporting and management. If following the live lab, skip this step! (a) Click the light bulb icon to add a new row. (b) Enter in a unique category name, a corresponding URL, and a detailed description of the category with intents that do not match any other category. Virtual Agent Framework (a) Select \"Virtual Agent Type\" from the drop down menu. In this example, select \" Watson Assistant Actions \". (b) Select preferred choice of enabling or disabling embedding links into returned responses. In this example, select \" Disable \". Click \"Next\" to save reported categories and the selected Virtual Agent. Tune - Tune for your Data Let's tune NeuralSeek for your data. (a) Select the preferred option for \"Which of these looks more like your data?\". For this example, select \" Important phrases are surrounded by many lines of text that explain them. \". The option \" Important phrases are surrounded by many lines of text that explain them \", describes data with more elaborate explanations with more extensive passages of text for a better understanding. The option \" Important phrases are surrounded by only a line or two of relevant information \", describes data with concise coverage of key phrases with just a line or two of necessary context. (b) Select the preferred option that best describes your data requirements. For this example, select \" I want to give lots of information to the LLM, and give it leeway to decide the answer. \" (c) Select the preferred option that best describes your data currency. For this example, select \" All of my documents are current and relevant. \". The option \" All of my documents are current and relevant \", describes data that is up-to-date. The option \" I have lots of old documents or blog posts, some with conflicting information. I need NeuralSeek to help with date prioritization \", describes data that may have conflicting or irrelevant details across different sources or documents. Click \"Next\" to save reported tuning configurations. Questions and Answers As questions are answered by NeuralSeek, we can automatically build out and maintain portions of your Virtual Agent. Use the buttons below to quickly generate Q&A content to bootstrap and test your Virtual Agent. Auto-Generate Questions will query the KnowledgeBase, ask NeuralSeek to generate insights and output a variety of test questions based on your corporate content. Click \"Submit\" to have NeuralSeek generate answers. Manually Input Questions will provide a blank test box for you to enter questions, one per line, based on your corporate content. Click \"Submit\" to have NeuralSeek generate answers. Upload Test Questions will provide a link to your local file explorer to upload a CSV file of test questions. The questions will be run through the Seek endpoint in parallel and scored. Please use the provided downloadable .csv file as a template for your questions. Input files must retain these column titles at a minimum, but you may add additional payload columns. Click \"Submit\" to have NeuralSeek generate answers. Ready NeuralSeek is ready to seek. NeuralSeek is now set up and ready to use.","title":"1.1 - Set Up NeuralSeek"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#module-11","text":"","title":"Module 1.1"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#add-neuralseek","text":"Log in to IBM Cloud . Search and select NeuralSeek from Catalog. (a) Select the Pay-per-answer plan type. (b) To agree to the third-party terms, in the bottom right, open and read the terms then check, \u201cI have read and agree to the following third-party terms\u201d. (c) To provision, click \u201cCreate\u201d. Please note that users are responsible for all incurred costs.","title":"Add NeuralSeek"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#launch-neuralseek","text":"Click \u201cLaunch NeuralSeek\u201d.","title":"Launch NeuralSeek"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#basics-getting-started","text":"First, we need a short writeup about your company or organization, focusing on the use-case for this instance of NeuralSeek. (a) Add a brief company or organization description. (b) Select \"Output Language\" from the drop down menu. In this example, select \" English \". It's best to match the language of your KnowledgeBase and questions, but NeuralSeek is able to translate between many languages. (c) Select preferred use of NeuralSeek instance. Will this instance of NeuralSeek be used internally within your organization, or is it external - customer facing? We'll use this info to pre-tune some safety parameters for you. In this example, select \" Internal \".","title":"Basics - Getting Started"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#data-connect-to-your-knowledgebase","text":"(a) Select KnowledgeBase. In this example \u201c Watson Discovery \u201d. (b) Select language. In this example \" English \".","title":"Data - Connect to your KnowledgeBase"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#add-knowledgebase-information","text":"User is responsible for providing selected KnowledgeBase details information. Since it takes time to set these up for yourself, we are going to be using the one that is already prepared for the learning lab, with read-only access. The actual values below will be provided during the course of this lab by the lab instructor. Please enter the following: (a) Add \"Discovery Service URL\". (b) Add \"Discovery API Key\". (c) Add \"Discovery Project ID\". Click the \"Test\" button to test the connection. Then, click \"Next\" to save KnowledgeBase configuration.","title":"Add KnowledgeBase Information"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#organize-outputs-and-categories","text":"","title":"Organize - Outputs and Categories"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#categorization","text":"Categorize your intents for easier reporting and management. If following the live lab, skip this step! (a) Click the light bulb icon to add a new row. (b) Enter in a unique category name, a corresponding URL, and a detailed description of the category with intents that do not match any other category.","title":"Categorization"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#virtual-agent-framework","text":"(a) Select \"Virtual Agent Type\" from the drop down menu. In this example, select \" Watson Assistant Actions \". (b) Select preferred choice of enabling or disabling embedding links into returned responses. In this example, select \" Disable \". Click \"Next\" to save reported categories and the selected Virtual Agent.","title":"Virtual Agent Framework"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#tune-tune-for-your-data","text":"Let's tune NeuralSeek for your data. (a) Select the preferred option for \"Which of these looks more like your data?\". For this example, select \" Important phrases are surrounded by many lines of text that explain them. \". The option \" Important phrases are surrounded by many lines of text that explain them \", describes data with more elaborate explanations with more extensive passages of text for a better understanding. The option \" Important phrases are surrounded by only a line or two of relevant information \", describes data with concise coverage of key phrases with just a line or two of necessary context. (b) Select the preferred option that best describes your data requirements. For this example, select \" I want to give lots of information to the LLM, and give it leeway to decide the answer. \" (c) Select the preferred option that best describes your data currency. For this example, select \" All of my documents are current and relevant. \". The option \" All of my documents are current and relevant \", describes data that is up-to-date. The option \" I have lots of old documents or blog posts, some with conflicting information. I need NeuralSeek to help with date prioritization \", describes data that may have conflicting or irrelevant details across different sources or documents. Click \"Next\" to save reported tuning configurations.","title":"Tune - Tune for your Data"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#questions-and-answers","text":"As questions are answered by NeuralSeek, we can automatically build out and maintain portions of your Virtual Agent. Use the buttons below to quickly generate Q&A content to bootstrap and test your Virtual Agent. Auto-Generate Questions will query the KnowledgeBase, ask NeuralSeek to generate insights and output a variety of test questions based on your corporate content. Click \"Submit\" to have NeuralSeek generate answers. Manually Input Questions will provide a blank test box for you to enter questions, one per line, based on your corporate content. Click \"Submit\" to have NeuralSeek generate answers. Upload Test Questions will provide a link to your local file explorer to upload a CSV file of test questions. The questions will be run through the Seek endpoint in parallel and scored. Please use the provided downloadable .csv file as a template for your questions. Input files must retain these column titles at a minimum, but you may add additional payload columns. Click \"Submit\" to have NeuralSeek generate answers.","title":"Questions and Answers"},{"location":"module1/module1_ibm/ibm_module1-1/ibm_module1-1/#ready","text":"NeuralSeek is ready to seek. NeuralSeek is now set up and ready to use.","title":"Ready"},{"location":"module1/module1_ibm/ibm_module1-2/ibm_module1-2/","text":"Module 1.2 Create Resource If you do not have watsonx Assistant, login to IBM Cloud . Click \u201cCreate Resource\u201d. Search the Catalog Search and select \u201cWatson Assistant\u201d. Create a Preferred Version (a) Select version. In this example, \u201cLite\u201d. (b) Read the Terms and check, \u201cI have read and agree to the following license agreements: Terms \u201d. (c) Click \u201cCreate\u201d. Launch watsonx Assistant Click \u201cLaunch Watson Assistant\u201d. Create Your First Assistant (a) Type assistant name. In this example, \u201c IBM Learning Lab: NeuralSeek with Watson \u201d (b) Type optional description. In this example, \u201c Learning experience to provide an immersive and hands-on approach to understanding the complexities of Watson and NeuralSeek. \u201d. (c) Select assistant language. In this example, \u201c English \u201d. (d) Click \u201cNext\u201d. Continue with the Watson Assistant Complete the required information. - (a) Select deployment plan, industry, team role, role, needs. - (b) Click \u201cNext\u201d. Customize Your Chat UI Complete the required information. - (a) Type assistant name, primary color, secondary color, accent color, and upload image. - (b) Click \u201cNext\u201d. Preview and Create Click \u201cCreate\u201d. The virtual agent IBM watsonx Assistant is now created and ready to be connected to NeuralSeek for use.","title":"1.2 - Set Up Virtual Agent"},{"location":"module1/module1_ibm/ibm_module1-2/ibm_module1-2/#module-12","text":"","title":"Module 1.2"},{"location":"module1/module1_ibm/ibm_module1-2/ibm_module1-2/#create-resource","text":"If you do not have watsonx Assistant, login to IBM Cloud . Click \u201cCreate Resource\u201d.","title":"Create Resource"},{"location":"module1/module1_ibm/ibm_module1-2/ibm_module1-2/#search-the-catalog","text":"Search and select \u201cWatson Assistant\u201d.","title":"Search the Catalog"},{"location":"module1/module1_ibm/ibm_module1-2/ibm_module1-2/#create-a-preferred-version","text":"(a) Select version. In this example, \u201cLite\u201d. (b) Read the Terms and check, \u201cI have read and agree to the following license agreements: Terms \u201d. (c) Click \u201cCreate\u201d.","title":"Create a Preferred Version"},{"location":"module1/module1_ibm/ibm_module1-2/ibm_module1-2/#launch-watsonx-assistant","text":"Click \u201cLaunch Watson Assistant\u201d.","title":"Launch watsonx Assistant"},{"location":"module1/module1_ibm/ibm_module1-2/ibm_module1-2/#create-your-first-assistant","text":"(a) Type assistant name. In this example, \u201c IBM Learning Lab: NeuralSeek with Watson \u201d (b) Type optional description. In this example, \u201c Learning experience to provide an immersive and hands-on approach to understanding the complexities of Watson and NeuralSeek. \u201d. (c) Select assistant language. In this example, \u201c English \u201d. (d) Click \u201cNext\u201d.","title":"Create Your First Assistant"},{"location":"module1/module1_ibm/ibm_module1-2/ibm_module1-2/#continue-with-the-watson-assistant","text":"Complete the required information. - (a) Select deployment plan, industry, team role, role, needs. - (b) Click \u201cNext\u201d.","title":"Continue with the Watson Assistant"},{"location":"module1/module1_ibm/ibm_module1-2/ibm_module1-2/#customize-your-chat-ui","text":"Complete the required information. - (a) Type assistant name, primary color, secondary color, accent color, and upload image. - (b) Click \u201cNext\u201d.","title":"Customize Your Chat UI"},{"location":"module1/module1_ibm/ibm_module1-2/ibm_module1-2/#preview-and-create","text":"Click \u201cCreate\u201d. The virtual agent IBM watsonx Assistant is now created and ready to be connected to NeuralSeek for use.","title":"Preview and Create"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/","text":"Module 1.3 Add NeuralSeek as a Custom Extension Open Integrations On the left menu, click \u201cIntegrations.\u201d Open Custom Extensions Click \u201cBuild custom extension.\u201d Custom Extensions Get Started Read the custom extension page \u201cGet started.\u201d Click \u201cNext.\u201d Basic Information (a) Enter in basic information, in this example the extension name is, \u201c IBM Learning Lab: NeuralSeek with Watson \u201d and the Extension description is, \u201c Participants work with NeuralSeek and Watson on AI services, gaining valuable insights into these technologies. \" (b) Click \u201cNext.\u201d Custom Extension Import OpenAPI To proceed you must add the NeuralSeek Api_file in the box \u201cDrag and drop file here or click to upload.\u201d Download the NeuralSeek OpenAPI_file Navigate to the NeuralSeek user interface. (a) On the top menu, click \u201cIntegrate\u201d (b) On the left menu, click \u201cWatson Custom Extension.\u201d (c) To download the file in point 3, click \u201cCustom Extension OpenApi_file. (d) View the downloaded json in the computer download menu. Upload the OpenAPI_file Return to IBM watsonx Assistant Custom extension page. Drag and drop or click and upload the NeuralSeek.json file into the Import OpenAPI box. Complete Upload View NeuralSeek.json file. Click \u201cNext.\u201d Complete Custom Extension Review extension. Click \u201cFinish.\u201d NeuralSeek is now added as a custom extension and integrated with the virtual agent IBM watsonx Assistant . Next, we need to authenticate the extension. Authenticate NeuralSeek with watsonx Assistant Get Started Authenticate NeuralSeek with watsonx Assistant. In this example it is, \u201c IBM Learning Lab: NeuralSeek with Watson \u201d. Navigate to Integrations (a) On the left menu, select \u201cIntegrations.\u201d (b) Search for the custom NeuralSeek extension, in this example it is, \u201c IBM Learning Lab: NeuralSeek and Watson. \u201d (c) Click \u201c+add.\u201d Add Extension Review custom extensions. Click \u201cAdd.\u201d View Get started. Click \u201cNext\u201d. Authentication Page Select authentication type as \u201cAPI Key auth.\u201d Retrieve API key auth from NeuralSeek Return to NeuralSeek custom extensions. On line 5, copy the API key for the \u201cAPI key auth\u201d. Paste API key Return to IBM watsonx Assistant. - (a) Paste the NeuralSeek API key into the API key text box. - (b) Click \u201cNext\u201d. Complete the Authentication Review the authentication. Click \u201cFinish\u201d. When it has updated, click \u201cClose\u201d. The custom NeuralSeek extension integrated with IBM watsonx Assistant is now authenticated and ready for use. Add NeuralSeek Starter Kit Actions Open Actions Open IBM watsonx Assistant. - (a) On the left menu, select \u201cActions\u201d. - (b) Click \u201cCreated by you\u201d. - (c) Click \u201cCreate action\u201d. Create an Action Select \u201cQuick Start with Template\". Build at Hyperspeed Select \u201cDo more with starter kits\u201d. Quick Start with Templates Search and select \u201cNeuralSeek\u201d. NeuralSeek Starter Kit Click \u201cSelect this starter kit\u201d. Selected Templates Click \u201cAdd templates\". View Inactive Actions (a) On the left menu, select \u201cActions\u201d. (b) Under All items, select \u201cCreated by you\u201d. On the right side under status, view the red circle on \u201cNeuralSeek search\u201d. At this stage, the circle is red because the integrations are added, but not yet connected to the underlying extension. (c) Open the action, click \u201cNeuralSeek search\u201d. Customer Starts With On the left menu, select option 3 highlighted in red \u201cThis step has no content.\u201d Delete Assignment On the right side of the set \u201cQuery_Context to Context\u201d click \u201cX.\u201d The reason why we are deleting it is because sometimes the query context provided by watsonx Assistant can be huge and exceeds the size of the request body to the API. Edit Extension Scroll down and click \u201cEdit extension\u201d. Choose an Extension Select NeuralSeek extension, in this example it is, \u201c IBM Learning Lab: NeuralSeek with Watson \u201d. Choose Operation Select \u201cSeek an answer from NeuralSeek\". Set Extension Parameters Select \u201cSession Variables\". Choose Parameters Select \u201cquery_text\u201d from the list options. Extension Setup Click \u201cApply\". Save Extension In the top right corner, click the \"Save\" icon. Close Extension In the top right corner, click \"x\" to close. Confirm Status On the right side, view the green circle with a check mark next to NeuralSeek search. The circle is now green because the integrations are properly connected to the extension and ready to use. NeuralSeek with IBM watsonx Assistant starter kit integrations are now connected and ready for use. Change Default to Generative AI Responses Set up a NeuralSeek call action to use to have generative AI respond to all queries, even questions not listed in watsonx Assistant. (a) On the left menu, select \u201cActions\u201d. (b) Under All items, select \u201cSet by assistant\u201d. (c) Select \u201cNo action matches\u201d. \"No action matches\" are cases when a user asks a question not listed in IBM Watsonx Assistant's predefined responses . Delete 2 No Action Matches Count On the left menu, on step 2, click the \u201cTrashcan\u201d icon. Confirm Delete Click \u201cDelete\u201d. Wait for the system to train. Delete Conditions (a) On the left menu, click 1. (b) Delete the condition, click the \u201cx\u201d. Open Preview Click \u201cPreview\u201d. View Default Responses Before Setting Up NeuralSeek Call (a) Type a random question, in this example it is, \u201c Why is the sky blue? \u201d (b) Press \u201cEnter\u201d. View the watsonx Assistant\u2019s default response, \u201cI\u2019m afraid I don\u2019t understand. Please rephrase your question.\u201d This is to test that the fallback action is being triggered properly. Delete Default Response In the assistant text box, delete \u201cI\u2019m afraid I don\u2019t understand. Please rephrase your question.\u201d. Add Subaction (a) Scroll to \u201cAnd then\u201d, click \u201cEnd the action\u201d. (b) Select \u201cGo to a subaction\u201d. Go to a Subaction Select \u201cNeuralSeek search\". Check Action (a) Check \u201cEnd this action after the other action is completed\u201d. (b) Click \u201cApply\u201d. Preview NeuralSeek Generative AI Response (a) In the lower right, click \u201cPreview\u201d and type a random question, in this example it is, \u201c Why is the sky blue? \u201d (b) Press \u201cEnter\u201d. View the NeuralSeek generative AI response. A NeuralSeek call action that allows for generative AI responses to all queries is now set up, tested, and ready to use.","title":"1.3 - Integrate NeuralSeek Custom Extension"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#module-13","text":"","title":"Module 1.3"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#add-neuralseek-as-a-custom-extension","text":"","title":"Add NeuralSeek as a Custom Extension"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#open-integrations","text":"On the left menu, click \u201cIntegrations.\u201d","title":"Open Integrations"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#open-custom-extensions","text":"Click \u201cBuild custom extension.\u201d","title":"Open Custom Extensions"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#custom-extensions-get-started","text":"Read the custom extension page \u201cGet started.\u201d Click \u201cNext.\u201d","title":"Custom Extensions Get Started"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#basic-information","text":"(a) Enter in basic information, in this example the extension name is, \u201c IBM Learning Lab: NeuralSeek with Watson \u201d and the Extension description is, \u201c Participants work with NeuralSeek and Watson on AI services, gaining valuable insights into these technologies. \" (b) Click \u201cNext.\u201d","title":"Basic Information"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#custom-extension-import-openapi","text":"To proceed you must add the NeuralSeek Api_file in the box \u201cDrag and drop file here or click to upload.\u201d","title":"Custom Extension Import OpenAPI"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#download-the-neuralseek-openapi_file","text":"Navigate to the NeuralSeek user interface. (a) On the top menu, click \u201cIntegrate\u201d (b) On the left menu, click \u201cWatson Custom Extension.\u201d (c) To download the file in point 3, click \u201cCustom Extension OpenApi_file. (d) View the downloaded json in the computer download menu.","title":"Download the NeuralSeek OpenAPI_file"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#upload-the-openapi_file","text":"Return to IBM watsonx Assistant Custom extension page. Drag and drop or click and upload the NeuralSeek.json file into the Import OpenAPI box.","title":"Upload the OpenAPI_file"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#complete-upload","text":"View NeuralSeek.json file. Click \u201cNext.\u201d","title":"Complete Upload"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#complete-custom-extension","text":"Review extension. Click \u201cFinish.\u201d NeuralSeek is now added as a custom extension and integrated with the virtual agent IBM watsonx Assistant . Next, we need to authenticate the extension.","title":"Complete Custom Extension"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#authenticate-neuralseek-with-watsonx-assistant","text":"","title":"Authenticate NeuralSeek with watsonx Assistant"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#get-started","text":"Authenticate NeuralSeek with watsonx Assistant. In this example it is, \u201c IBM Learning Lab: NeuralSeek with Watson \u201d.","title":"Get Started"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#navigate-to-integrations","text":"(a) On the left menu, select \u201cIntegrations.\u201d (b) Search for the custom NeuralSeek extension, in this example it is, \u201c IBM Learning Lab: NeuralSeek and Watson. \u201d (c) Click \u201c+add.\u201d","title":"Navigate to Integrations"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#add-extension","text":"Review custom extensions. Click \u201cAdd.\u201d View Get started. Click \u201cNext\u201d.","title":"Add Extension"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#authentication-page","text":"Select authentication type as \u201cAPI Key auth.\u201d","title":"Authentication Page"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#retrieve-api-key-auth-from-neuralseek","text":"Return to NeuralSeek custom extensions. On line 5, copy the API key for the \u201cAPI key auth\u201d.","title":"Retrieve API key auth from NeuralSeek"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#paste-api-key","text":"Return to IBM watsonx Assistant. - (a) Paste the NeuralSeek API key into the API key text box. - (b) Click \u201cNext\u201d.","title":"Paste API key"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#complete-the-authentication","text":"Review the authentication. Click \u201cFinish\u201d. When it has updated, click \u201cClose\u201d. The custom NeuralSeek extension integrated with IBM watsonx Assistant is now authenticated and ready for use.","title":"Complete the Authentication"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#add-neuralseek-starter-kit-actions","text":"","title":"Add NeuralSeek Starter Kit Actions"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#open-actions","text":"Open IBM watsonx Assistant. - (a) On the left menu, select \u201cActions\u201d. - (b) Click \u201cCreated by you\u201d. - (c) Click \u201cCreate action\u201d.","title":"Open Actions"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#create-an-action","text":"Select \u201cQuick Start with Template\".","title":"Create an Action"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#build-at-hyperspeed","text":"Select \u201cDo more with starter kits\u201d.","title":"Build at Hyperspeed"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#quick-start-with-templates","text":"Search and select \u201cNeuralSeek\u201d.","title":"Quick Start with Templates"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#neuralseek-starter-kit","text":"Click \u201cSelect this starter kit\u201d.","title":"NeuralSeek Starter Kit"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#selected-templates","text":"Click \u201cAdd templates\".","title":"Selected Templates"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#view-inactive-actions","text":"(a) On the left menu, select \u201cActions\u201d. (b) Under All items, select \u201cCreated by you\u201d. On the right side under status, view the red circle on \u201cNeuralSeek search\u201d. At this stage, the circle is red because the integrations are added, but not yet connected to the underlying extension. (c) Open the action, click \u201cNeuralSeek search\u201d.","title":"View Inactive Actions"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#customer-starts-with","text":"On the left menu, select option 3 highlighted in red \u201cThis step has no content.\u201d","title":"Customer Starts With"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#delete-assignment","text":"On the right side of the set \u201cQuery_Context to Context\u201d click \u201cX.\u201d The reason why we are deleting it is because sometimes the query context provided by watsonx Assistant can be huge and exceeds the size of the request body to the API.","title":"Delete Assignment"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#edit-extension","text":"Scroll down and click \u201cEdit extension\u201d.","title":"Edit Extension"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#choose-an-extension","text":"Select NeuralSeek extension, in this example it is, \u201c IBM Learning Lab: NeuralSeek with Watson \u201d.","title":"Choose an Extension"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#choose-operation","text":"Select \u201cSeek an answer from NeuralSeek\".","title":"Choose Operation"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#set-extension-parameters","text":"Select \u201cSession Variables\".","title":"Set Extension Parameters"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#choose-parameters","text":"Select \u201cquery_text\u201d from the list options.","title":"Choose Parameters"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#extension-setup","text":"Click \u201cApply\".","title":"Extension Setup"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#save-extension","text":"In the top right corner, click the \"Save\" icon.","title":"Save Extension"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#close-extension","text":"In the top right corner, click \"x\" to close.","title":"Close Extension"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#confirm-status","text":"On the right side, view the green circle with a check mark next to NeuralSeek search. The circle is now green because the integrations are properly connected to the extension and ready to use. NeuralSeek with IBM watsonx Assistant starter kit integrations are now connected and ready for use.","title":"Confirm Status"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#change-default-to-generative-ai-responses","text":"Set up a NeuralSeek call action to use to have generative AI respond to all queries, even questions not listed in watsonx Assistant. (a) On the left menu, select \u201cActions\u201d. (b) Under All items, select \u201cSet by assistant\u201d. (c) Select \u201cNo action matches\u201d. \"No action matches\" are cases when a user asks a question not listed in IBM Watsonx Assistant's predefined responses .","title":"Change Default to Generative AI Responses"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#delete-2-no-action-matches-count","text":"On the left menu, on step 2, click the \u201cTrashcan\u201d icon.","title":"Delete 2 No Action Matches Count"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#confirm-delete","text":"Click \u201cDelete\u201d. Wait for the system to train.","title":"Confirm Delete"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#delete-conditions","text":"(a) On the left menu, click 1. (b) Delete the condition, click the \u201cx\u201d.","title":"Delete Conditions"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#open-preview","text":"Click \u201cPreview\u201d.","title":"Open Preview"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#view-default-responses-before-setting-up-neuralseek-call","text":"(a) Type a random question, in this example it is, \u201c Why is the sky blue? \u201d (b) Press \u201cEnter\u201d. View the watsonx Assistant\u2019s default response, \u201cI\u2019m afraid I don\u2019t understand. Please rephrase your question.\u201d This is to test that the fallback action is being triggered properly.","title":"View Default Responses Before Setting Up NeuralSeek Call"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#delete-default-response","text":"In the assistant text box, delete \u201cI\u2019m afraid I don\u2019t understand. Please rephrase your question.\u201d.","title":"Delete Default Response"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#add-subaction","text":"(a) Scroll to \u201cAnd then\u201d, click \u201cEnd the action\u201d. (b) Select \u201cGo to a subaction\u201d.","title":"Add Subaction"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#go-to-a-subaction","text":"Select \u201cNeuralSeek search\".","title":"Go to a Subaction"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#check-action","text":"(a) Check \u201cEnd this action after the other action is completed\u201d. (b) Click \u201cApply\u201d.","title":"Check Action"},{"location":"module1/module1_ibm/ibm_module1-3/ibm_module1-3/#preview-neuralseek-generative-ai-response","text":"(a) In the lower right, click \u201cPreview\u201d and type a random question, in this example it is, \u201c Why is the sky blue? \u201d (b) Press \u201cEnter\u201d. View the NeuralSeek generative AI response. A NeuralSeek call action that allows for generative AI responses to all queries is now set up, tested, and ready to use.","title":"Preview NeuralSeek Generative AI Response"},{"location":"module2/module2/","text":"Module 2: Seeking Answers The purpose of Module 2: Seeking Answers is to highlight the key features of NeuralSeek that are instrumental in training virtual agents, including customer-facing chatbots and Natural Language Processing systems. These features not only facilitate natural language responses but also ensure the prevention of hallucinated outputs, automate language translation processes, and protect user's private identifying information. Recognizing that the quality of generated AI responses hinges on the integrity of the underlying data, the tools featured in this module intentionally provide resources for human oversight to prevent errors and avoid biases. Level: Intermediate Time: 20 minutes No Code Required","title":"Overview"},{"location":"module2/module2/#module-2-seeking-answers","text":"The purpose of Module 2: Seeking Answers is to highlight the key features of NeuralSeek that are instrumental in training virtual agents, including customer-facing chatbots and Natural Language Processing systems. These features not only facilitate natural language responses but also ensure the prevention of hallucinated outputs, automate language translation processes, and protect user's private identifying information. Recognizing that the quality of generated AI responses hinges on the integrity of the underlying data, the tools featured in this module intentionally provide resources for human oversight to prevent errors and avoid biases. Level: Intermediate Time: 20 minutes No Code Required","title":"Module 2: Seeking Answers"},{"location":"module2/module2-1/module2-1/","text":"NeuralSeek's Seek feature enables users to test questions and generate answers using content from their connected KnowledgeBase. To ensure transparency between the sources and answers, NeuralSeek reveals the specific origin of the words and phrases that are generated. Semantic match scores are employed to compare the generated responses with the original documentation, providing a clear understanding of the alignment between the response and the meaning conveyed in source documents. This process ensures accuracy and instills confidence in the reliability of the responses generated by NeuralSeek. Seek an answer not in the KnowledgeBase (a) On the top menu, click Seek . (b) In the text box type the question. For this example: What is the best cereal? . (c) Click Seek . (d) View the low KnowledgeBase Confidence and KnowledgeBase Coverage. There is no content in the selected KnowledgeBase resources on the best cereal type. Compare Confidence Score Ask a question based on the content in the connected KnowledgeBase. (a) In the text box type the question, in this example, What is NeuralSeek's Seek feature? . (b) Click Seek . (c) View the large and highlighted text in the Generative AI response, this response is generated from content found in the selected KnowledgeBase resources. View content NeuralSeek offers Answer Provenance capabilities which add color-coded highlights to keywords in the generated answer matching where in the source documentation the answer is being pulled from. (a) Match the colors. The color of the highlighted text in the AI-generated response matches the listed KnowledgeBase content. (b) View the high alignment in this example, most content is over 95% with a few resources at or near 90%. Compare a more nuanced question (a) Type, Why should I use NeuralSeek with a KnowledgeBase instead of just ChatGPT? into the search bar and click Seek . (b) View the single words highlighted in multiple colors. Unlike the question, What is NeuralSeek's Seek feature? , this response is keywords and reference materials. Seek information Scroll down to view some key insights related to the generated answer. Information Output Description Total Response Time This number indicates the total amount of time for a response to generate in seconds. Semantic Match % This percentage is the overall match score that indicates how much NeuralSeek believes that the responses are well aligned with the underlying ground truth from the KnowledgeBase. The higher the percentage is, the more accurate and relevant the answer is based on the truth. Semantic Analysis A summary describing why NeuralSeek calculated the matching score in an easy-to-understand syntax. This gives users a good understanding why the answer was given either a high or low score. KnowledgeBase Confidence % This percentage indicates how confident the KnowledgeBase thinks the retrieved sources are related to the given question. KnowledgeBase Coverage % This percentage indicates how much coverage the KnowledgeBase thinks the retrieved sources are related to the given question. KnowledgeBase Response Time This number indicates the amount of time for the KnowledgeBase to generate a response in seconds. KnowledgeBase Results This number indicates the amount of retrieved sources the KnowledgeBase thinks are related to the given question. Additional descriptions NeuralSeek provides a brief description of each source referenced in the KnowledgeBase. (a) Click on the top section to expand the details. (b) To view the actual source, click the blue text. Ask additional questions Optionally, ask a variety of questions that pertain to your knowledge source to continue exploring. Here are some sample questions to ask based on our NeuralSeek KnowledgeBase: How does NeuralSeek protect private information? What languages do NeuralSeek support? Why is user intent categorization important?","title":"2.1 - Seeking Answers"},{"location":"module2/module2-1/module2-1/#seek-an-answer-not-in-the-knowledgebase","text":"(a) On the top menu, click Seek . (b) In the text box type the question. For this example: What is the best cereal? . (c) Click Seek . (d) View the low KnowledgeBase Confidence and KnowledgeBase Coverage. There is no content in the selected KnowledgeBase resources on the best cereal type.","title":"Seek an answer not in the KnowledgeBase"},{"location":"module2/module2-1/module2-1/#compare-confidence-score","text":"Ask a question based on the content in the connected KnowledgeBase. (a) In the text box type the question, in this example, What is NeuralSeek's Seek feature? . (b) Click Seek . (c) View the large and highlighted text in the Generative AI response, this response is generated from content found in the selected KnowledgeBase resources.","title":"Compare Confidence Score"},{"location":"module2/module2-1/module2-1/#view-content","text":"NeuralSeek offers Answer Provenance capabilities which add color-coded highlights to keywords in the generated answer matching where in the source documentation the answer is being pulled from. (a) Match the colors. The color of the highlighted text in the AI-generated response matches the listed KnowledgeBase content. (b) View the high alignment in this example, most content is over 95% with a few resources at or near 90%.","title":"View content"},{"location":"module2/module2-1/module2-1/#compare-a-more-nuanced-question","text":"(a) Type, Why should I use NeuralSeek with a KnowledgeBase instead of just ChatGPT? into the search bar and click Seek . (b) View the single words highlighted in multiple colors. Unlike the question, What is NeuralSeek's Seek feature? , this response is keywords and reference materials.","title":"Compare a more nuanced question"},{"location":"module2/module2-1/module2-1/#seek-information","text":"Scroll down to view some key insights related to the generated answer. Information Output Description Total Response Time This number indicates the total amount of time for a response to generate in seconds. Semantic Match % This percentage is the overall match score that indicates how much NeuralSeek believes that the responses are well aligned with the underlying ground truth from the KnowledgeBase. The higher the percentage is, the more accurate and relevant the answer is based on the truth. Semantic Analysis A summary describing why NeuralSeek calculated the matching score in an easy-to-understand syntax. This gives users a good understanding why the answer was given either a high or low score. KnowledgeBase Confidence % This percentage indicates how confident the KnowledgeBase thinks the retrieved sources are related to the given question. KnowledgeBase Coverage % This percentage indicates how much coverage the KnowledgeBase thinks the retrieved sources are related to the given question. KnowledgeBase Response Time This number indicates the amount of time for the KnowledgeBase to generate a response in seconds. KnowledgeBase Results This number indicates the amount of retrieved sources the KnowledgeBase thinks are related to the given question.","title":"Seek information"},{"location":"module2/module2-1/module2-1/#additional-descriptions","text":"NeuralSeek provides a brief description of each source referenced in the KnowledgeBase. (a) Click on the top section to expand the details. (b) To view the actual source, click the blue text.","title":"Additional descriptions"},{"location":"module2/module2-1/module2-1/#ask-additional-questions","text":"Optionally, ask a variety of questions that pertain to your knowledge source to continue exploring. Here are some sample questions to ask based on our NeuralSeek KnowledgeBase: How does NeuralSeek protect private information? What languages do NeuralSeek support? Why is user intent categorization important?","title":"Ask additional questions"},{"location":"module2/module2-2/module2-2/","text":"Caching NeuralSeek uses caching strategy when searching through a corporate KnowledgeBase to enhance performance and reduce computational cost during its operation. NeuralSeek also utilizes two types of caches for both your edited answers and generated answers that can serve cached answers to user questions in order to speed up response times and produce more consistent results. Inaccurate Answer Example Navigate to NeuralSeek's Curate tab to view our inaccurate answer example. (a) Select an intent by clicking the dropdown caret icon. (b) Read the answer generated for that specific intent. It is possible for NeuralSeek to generate an inaccurate answer because the content in KnowledgeBase is outdated or missing. Manually Correct Generative AI responses. You can edit any answer, and the edited response will be used when you curate and export into a virtual agent. Edited responses are also used to train future generated answers. (a) Click the text box to update the answer for accuracy. For example, add this text to the answer: The best cereal is Cheerios. (b) Click Save. The newly added answer will be marked as Edited . Intent Matching and Categorization Navigate to NeuralSeek's Configure tab and expand the Intent Matching & Cache Configuration details. Here, we can select how strict we want to be about matching intents, this is helpful especially if you have edited answers that you want users to hit more. Edited Answer Cache Scale This sliding scale allows user to set how many different edited answers exist for a user question, and will serve an edited answer at least that many times. Set the sliding scale to 1 to prioritize the edited answer cache. Normal Answer Cache Scale Edited answers have priority in the Normal Answer Cache. This sliding scale allows user to set how many different answers exist for a user question, and will serve a recent answer if the documentation has not changed, or an edited answer if available. Set the sliding scale to 1 to prioritize the edited answer cache. Save Options Scroll down to the bottom of the screen and click the red Save button. Seek Query Navigate to NeuralSeek's Seek tab. Input the inaccurate example question and click Seek. Review Output Notice how the generated output is the newly edited answer. The total response time is less than a second, because serving cached answers speeds up response times. The semantic score is 100% and there is an indication next to it showing the answer is Cached. The KnowledgeBase Confidence and Coverage scores are 100% when an edited answer is served. Edited answers are retained until updated or deleted, even if the source documentation changes, so use caution to be sure edited answers contain relevant information.","title":"2.2 - Caching Answers"},{"location":"module2/module2-2/module2-2/#caching","text":"NeuralSeek uses caching strategy when searching through a corporate KnowledgeBase to enhance performance and reduce computational cost during its operation. NeuralSeek also utilizes two types of caches for both your edited answers and generated answers that can serve cached answers to user questions in order to speed up response times and produce more consistent results.","title":"Caching"},{"location":"module2/module2-2/module2-2/#inaccurate-answer-example","text":"Navigate to NeuralSeek's Curate tab to view our inaccurate answer example. (a) Select an intent by clicking the dropdown caret icon. (b) Read the answer generated for that specific intent. It is possible for NeuralSeek to generate an inaccurate answer because the content in KnowledgeBase is outdated or missing.","title":"Inaccurate Answer Example"},{"location":"module2/module2-2/module2-2/#manually-correct-generative-ai-responses","text":"You can edit any answer, and the edited response will be used when you curate and export into a virtual agent. Edited responses are also used to train future generated answers. (a) Click the text box to update the answer for accuracy. For example, add this text to the answer: The best cereal is Cheerios. (b) Click Save. The newly added answer will be marked as Edited .","title":"Manually Correct Generative AI responses."},{"location":"module2/module2-2/module2-2/#intent-matching-and-categorization","text":"Navigate to NeuralSeek's Configure tab and expand the Intent Matching & Cache Configuration details. Here, we can select how strict we want to be about matching intents, this is helpful especially if you have edited answers that you want users to hit more.","title":"Intent Matching and Categorization"},{"location":"module2/module2-2/module2-2/#edited-answer-cache-scale","text":"This sliding scale allows user to set how many different edited answers exist for a user question, and will serve an edited answer at least that many times. Set the sliding scale to 1 to prioritize the edited answer cache.","title":"Edited Answer Cache Scale"},{"location":"module2/module2-2/module2-2/#normal-answer-cache-scale","text":"Edited answers have priority in the Normal Answer Cache. This sliding scale allows user to set how many different answers exist for a user question, and will serve a recent answer if the documentation has not changed, or an edited answer if available. Set the sliding scale to 1 to prioritize the edited answer cache.","title":"Normal Answer Cache Scale"},{"location":"module2/module2-2/module2-2/#save-options","text":"Scroll down to the bottom of the screen and click the red Save button.","title":"Save Options"},{"location":"module2/module2-2/module2-2/#seek-query","text":"Navigate to NeuralSeek's Seek tab. Input the inaccurate example question and click Seek.","title":"Seek Query"},{"location":"module2/module2-2/module2-2/#review-output","text":"Notice how the generated output is the newly edited answer. The total response time is less than a second, because serving cached answers speeds up response times. The semantic score is 100% and there is an indication next to it showing the answer is Cached. The KnowledgeBase Confidence and Coverage scores are 100% when an edited answer is served. Edited answers are retained until updated or deleted, even if the source documentation changes, so use caution to be sure edited answers contain relevant information.","title":"Review Output"},{"location":"module2/module2-3/module2-3/","text":"As users ask questions to NeuralSeek, their questions and the generated answers will appear in NeuralSeek's Curate section. Questions will be grouped into recommended intents, and it is important to note that a questions and answer pair may exist in multiple proposed intents of different specificity. It is up to you to choose which specificity level is best for your use case. View chatbot preview questions in NeuralSeek Login to the NeuralSeek User Interface. On the top menu, click the \u201cCurate\u201d tab. Compare Coverage Score Users are able to compare coverage scores between intents. (a) Compare the high coverage score for the question, \u201c What is NeuralSeek's Seek feature? \u201d. (b) Compare the low coverage score for the question, \u201c What is the best cereal? \u201d. There is no source information in the selected KnowledgeBase on why the sky is blue, but there is source information on NeuralSeek's features, which explains the difference in coverage scores. Additional actions When you click one of the answers, the system automatically notifies you of actions you may perform on the row via the blue toolbar above. Click \u201cDelete\u201d to remove. Click \u201cMerge\u201d to merge with other checked seeks. Click \u201cFlag\u201d to return to later. Click \u201cDownload to CSV\u201d to collaborate with subject-matter experts. Click \u201cEdit Category\u201d to place into a category. Click \"Export\" to download a basefile for uploading to your virtual assistant. Click \"Import\" to upload a basefile from your virtual assistant. NeuralSeek will merge exported content with this basefile. Export Curate Intents NeuralSeek makes bootstrapping your virtual agent project easy with its Export/Import abilities within the Curate tab. Select desired intents by clicking the box next to the Intent. Click the blue Export button at the top of the screen to download the respective file type based on your connected Virtual Assistant framework. File types include: actions.json file for Watson Assistant Actions lex.zip file for AWS LexV2 Adding Intents to Virtual Agent Upload these files into their respective virtual agent platforms to bootstrap your project with manually curated intents. IBM watsonx Assistant Navigate to your watsonx Assistant project and click on Actions. In the top right corner, click the gear icon to open Global Settings Click Upload/Download, and click the download button to download a JSON file of the existing content in your virtual agent. A JSON file will be saved to your local machine. Navigate to the Curate Tab of NeuralSeek Click the Import Base button to upload the JSON file from the virtual agent. Now, select one or more intents which you want to import into watsonx Assistant. You will notice a new button is display which is Export to Watson Assistant Actions. It will download a JSON file called actions.json which will contain the selected intents that you want to convert it into Watson Assistant Actions. Navigate back to watsonx Assistant. At the same page where you just downloaded the JSON, click to Upload the actions.json file downloaded from NeuralSeek. You will see a warning message. Click Upload and replace . To view the newly uploaded intents, close this page, and you will see the exported actions appear on your actions list. By clicking one of the actions, you should be able to see the populated list of the questions generated by NeuralSeek. AWS Lex Log into AWS Management Console and navigate to AWS Lex > Bots. You should see a list of available bots to merge with NeuraSeek. In the Bots list in the main view, select the desired bot and click Action > Export. An Export Bot: dialog is shown. Leave all the default values and click Export. A blue banner is shown to indicate exporting followed by a green banner when successfully exported/downloaded. Navigate into your NeuralSeek instance and click on the Curate tab. Click on the Import Base AWS Lex V2 button in the upper right corner. Import the zipped AWS Lex file you exported from the Lex bot. The button will switch to Base AWS Lex V2 Uploaded . After import, intents will not get added to the content list, but duplicates will show an indicator if certain intents are already present. Select the desired intents that you want to export into AWS Lex by checking the boxes next to the intent. Upon selection, a new button Export to AWS Lex V2 will appear. Click the button to download a zipped file containing the intents. Navigate back to the Amazon Lex > Bots screen in the AWS Management Console, and click Actions > Import. Fill in the new Bot name, browse for the zip file, set the COPPA yes/no, set the IAM permissions, and then scroll down and click Import. You'll see a blue banner that the bot is being imported followed by a successfully imported banner. Find the imported bot in the bots list and open it by clicking on its name. The details for the merged bot is shown. Notice the Intents section in the left pane has both the original intents and the NeuralSeek intents merged into a single bot. Click the build button. You can now test the newly imported intents. Round-Trip Monitoring Navigate to the Integrate tab within NeuralSeek. The available options containing \"Logs\" provide step-by-step instruction on implementing Round-Trip monitoring on deployed NeuralSeek Intents specific to the cloud provider. Enabling this feature aids in keeping source data up-to-date for optimal answer generation. When NeuralSeek curated intents imported into the Virtual Agent are hit, a call back to NeuralSeek occurs which monitors the curated intents for outdated information, and alerts the user of necessary updates based on changes to relevant documentation in the connected KnowledgeBase. Inside of NeuralSeek's Curate screen, this would look like:","title":"2.3 - Curated Intents"},{"location":"module2/module2-3/module2-3/#view-chatbot-preview-questions-in-neuralseek","text":"Login to the NeuralSeek User Interface. On the top menu, click the \u201cCurate\u201d tab.","title":"View chatbot preview questions in NeuralSeek"},{"location":"module2/module2-3/module2-3/#compare-coverage-score","text":"Users are able to compare coverage scores between intents. (a) Compare the high coverage score for the question, \u201c What is NeuralSeek's Seek feature? \u201d. (b) Compare the low coverage score for the question, \u201c What is the best cereal? \u201d. There is no source information in the selected KnowledgeBase on why the sky is blue, but there is source information on NeuralSeek's features, which explains the difference in coverage scores.","title":"Compare Coverage Score"},{"location":"module2/module2-3/module2-3/#additional-actions","text":"When you click one of the answers, the system automatically notifies you of actions you may perform on the row via the blue toolbar above. Click \u201cDelete\u201d to remove. Click \u201cMerge\u201d to merge with other checked seeks. Click \u201cFlag\u201d to return to later. Click \u201cDownload to CSV\u201d to collaborate with subject-matter experts. Click \u201cEdit Category\u201d to place into a category. Click \"Export\" to download a basefile for uploading to your virtual assistant. Click \"Import\" to upload a basefile from your virtual assistant. NeuralSeek will merge exported content with this basefile.","title":"Additional actions"},{"location":"module2/module2-3/module2-3/#export-curate-intents","text":"NeuralSeek makes bootstrapping your virtual agent project easy with its Export/Import abilities within the Curate tab. Select desired intents by clicking the box next to the Intent. Click the blue Export button at the top of the screen to download the respective file type based on your connected Virtual Assistant framework. File types include: actions.json file for Watson Assistant Actions lex.zip file for AWS LexV2","title":"Export Curate Intents"},{"location":"module2/module2-3/module2-3/#adding-intents-to-virtual-agent","text":"Upload these files into their respective virtual agent platforms to bootstrap your project with manually curated intents.","title":"Adding Intents to Virtual Agent"},{"location":"module2/module2-3/module2-3/#ibm-watsonx-assistant","text":"Navigate to your watsonx Assistant project and click on Actions. In the top right corner, click the gear icon to open Global Settings Click Upload/Download, and click the download button to download a JSON file of the existing content in your virtual agent. A JSON file will be saved to your local machine. Navigate to the Curate Tab of NeuralSeek Click the Import Base button to upload the JSON file from the virtual agent. Now, select one or more intents which you want to import into watsonx Assistant. You will notice a new button is display which is Export to Watson Assistant Actions. It will download a JSON file called actions.json which will contain the selected intents that you want to convert it into Watson Assistant Actions. Navigate back to watsonx Assistant. At the same page where you just downloaded the JSON, click to Upload the actions.json file downloaded from NeuralSeek. You will see a warning message. Click Upload and replace . To view the newly uploaded intents, close this page, and you will see the exported actions appear on your actions list. By clicking one of the actions, you should be able to see the populated list of the questions generated by NeuralSeek.","title":"IBM watsonx Assistant"},{"location":"module2/module2-3/module2-3/#aws-lex","text":"Log into AWS Management Console and navigate to AWS Lex > Bots. You should see a list of available bots to merge with NeuraSeek. In the Bots list in the main view, select the desired bot and click Action > Export. An Export Bot: dialog is shown. Leave all the default values and click Export. A blue banner is shown to indicate exporting followed by a green banner when successfully exported/downloaded. Navigate into your NeuralSeek instance and click on the Curate tab. Click on the Import Base AWS Lex V2 button in the upper right corner. Import the zipped AWS Lex file you exported from the Lex bot. The button will switch to Base AWS Lex V2 Uploaded . After import, intents will not get added to the content list, but duplicates will show an indicator if certain intents are already present. Select the desired intents that you want to export into AWS Lex by checking the boxes next to the intent. Upon selection, a new button Export to AWS Lex V2 will appear. Click the button to download a zipped file containing the intents. Navigate back to the Amazon Lex > Bots screen in the AWS Management Console, and click Actions > Import. Fill in the new Bot name, browse for the zip file, set the COPPA yes/no, set the IAM permissions, and then scroll down and click Import. You'll see a blue banner that the bot is being imported followed by a successfully imported banner. Find the imported bot in the bots list and open it by clicking on its name. The details for the merged bot is shown. Notice the Intents section in the left pane has both the original intents and the NeuralSeek intents merged into a single bot. Click the build button. You can now test the newly imported intents.","title":"AWS Lex"},{"location":"module2/module2-3/module2-3/#round-trip-monitoring","text":"Navigate to the Integrate tab within NeuralSeek. The available options containing \"Logs\" provide step-by-step instruction on implementing Round-Trip monitoring on deployed NeuralSeek Intents specific to the cloud provider. Enabling this feature aids in keeping source data up-to-date for optimal answer generation. When NeuralSeek curated intents imported into the Virtual Agent are hit, a call back to NeuralSeek occurs which monitors the curated intents for outdated information, and alerts the user of necessary updates based on changes to relevant documentation in the connected KnowledgeBase. Inside of NeuralSeek's Curate screen, this would look like:","title":"Round-Trip Monitoring"},{"location":"module2/module2-4/module2-4/","text":"Users are able to create categories using natural language descriptions to control how intents in user questions can be categorized. Typically, a question would be automatically categorized as FAQ , but users are able to provide additional custom categories. Once categorization is enabled, the Curate and Analytics screens will change to show groupings around categories. Users may move intents into categories manually through the Curate tab or the CSV download/edit features. The edits made will be used to train the system for future categorization events. Add Intent Categories Navigate to the Configure tab within NeuralSeek, and expand the Intent Categorization field. Click the light bulb icon to add a new category row. Add a title to the category in the first box on the left side. For example, add: Virtual Agents . Underneath, add a link to the source documentation containing information about the category. For example, add https://documentation.neuralseek.com/integrations/supported_virtual_agents/supported_virtual_agents/ . Describe Categories The box on the right side is where users are able to add a natural language description of the category. Add a description of the category. For example, add: Virtual Agents that are supported by NeuralSeek. . Click the red Save icon at the bottom of the screen to save the newly added Intent Category. Seek Answers based on Intent Category Navigate to the Seek tab within NeuralSeek. Ask a question involving the newly created Intent Category, so the Intent will appear in the Curate and Analytics screen as well. For example, seek: What Virtual Agents are supported by NeuralSeek? , or Does NeuralSeek support Virtual Agent integration? . View Intent Categories Navigate to the Curate tab within NeuralSeek. Notice how there is a number 1 next to the new intent underneath the Category label. Click the number to view the name of the category that intent is now placed in. Optionally, you can edit which category Intents fall into by selecting from the dropdown menu. Navigate to the Analytics tab within NeuralSeek to view the Intent history of the newly created category as well. PII Handling NeuralSeek features an advanced Personal Identifiable Information (PII) detection routine that automatically identifies any PII within user inputs. It allows users to maintain a secure environment while still providing accurate responses to user queries. Turn Off \"Force Answers from the KnowledgeBase\" Navigate to the Configure screen in NeuralSeek and expand the Answer Engineering & Preferences details. Change the \"Force Answers from the KnowledgeBase\" selection to False . We configure this setting for optimal answer generation for this next example, since the information will not be in our source documentation. Set LLM - Based PII Filters Expand the Personal Identifiable Information (PII) Handling details. Click the light bulb icon to add a new row. Add an example sentence. For example: I graduated college from JMU. In the box to the right, add the PII element of the example sentence. In this example: JMU . Click the red Save icon at the bottom of the screen. Seek a Query Navigate to the Seek screen of NeuralSeek. Seek the question being sure to reference the PII. In this example, seek: What colleges are in Virginia? Notice the answer is vague and does not include information about specific colleges in that area. Inspect PII Navigate to the Curate screen in NeuralSeek. Here, we can see that newly created intent with a symbol indicating that this intent contains PII. Expand the intent to view the answers. Notice how the location of \"Virginia\" that we asked in the question is masked to hide the PII. Ask an Additional Question Optionally, you can continue to seek queries and view how the related PII is masked in the Curate screen. For example, seek the question, Where is JMU located? . The answer will be vague and not contain information regarding the location due to it containing PII. In the Curate screen, the intent will appear with the same symbol indicating PII. Inside the query, JMU will also be masked to protect the PII.","title":"2.4 - Intent Categorization"},{"location":"module2/module2-4/module2-4/#add-intent-categories","text":"Navigate to the Configure tab within NeuralSeek, and expand the Intent Categorization field. Click the light bulb icon to add a new category row. Add a title to the category in the first box on the left side. For example, add: Virtual Agents . Underneath, add a link to the source documentation containing information about the category. For example, add https://documentation.neuralseek.com/integrations/supported_virtual_agents/supported_virtual_agents/ .","title":"Add Intent Categories"},{"location":"module2/module2-4/module2-4/#describe-categories","text":"The box on the right side is where users are able to add a natural language description of the category. Add a description of the category. For example, add: Virtual Agents that are supported by NeuralSeek. . Click the red Save icon at the bottom of the screen to save the newly added Intent Category.","title":"Describe Categories"},{"location":"module2/module2-4/module2-4/#seek-answers-based-on-intent-category","text":"Navigate to the Seek tab within NeuralSeek. Ask a question involving the newly created Intent Category, so the Intent will appear in the Curate and Analytics screen as well. For example, seek: What Virtual Agents are supported by NeuralSeek? , or Does NeuralSeek support Virtual Agent integration? .","title":"Seek Answers based on Intent Category"},{"location":"module2/module2-4/module2-4/#view-intent-categories","text":"Navigate to the Curate tab within NeuralSeek. Notice how there is a number 1 next to the new intent underneath the Category label. Click the number to view the name of the category that intent is now placed in. Optionally, you can edit which category Intents fall into by selecting from the dropdown menu. Navigate to the Analytics tab within NeuralSeek to view the Intent history of the newly created category as well.","title":"View Intent Categories"},{"location":"module2/module2-4/module2-4/#pii-handling","text":"NeuralSeek features an advanced Personal Identifiable Information (PII) detection routine that automatically identifies any PII within user inputs. It allows users to maintain a secure environment while still providing accurate responses to user queries.","title":"PII Handling"},{"location":"module2/module2-4/module2-4/#turn-off-force-answers-from-the-knowledgebase","text":"Navigate to the Configure screen in NeuralSeek and expand the Answer Engineering & Preferences details. Change the \"Force Answers from the KnowledgeBase\" selection to False . We configure this setting for optimal answer generation for this next example, since the information will not be in our source documentation.","title":"Turn Off \"Force Answers from the KnowledgeBase\""},{"location":"module2/module2-4/module2-4/#set-llm-based-pii-filters","text":"Expand the Personal Identifiable Information (PII) Handling details. Click the light bulb icon to add a new row. Add an example sentence. For example: I graduated college from JMU. In the box to the right, add the PII element of the example sentence. In this example: JMU . Click the red Save icon at the bottom of the screen.","title":"Set LLM - Based PII Filters"},{"location":"module2/module2-4/module2-4/#seek-a-query","text":"Navigate to the Seek screen of NeuralSeek. Seek the question being sure to reference the PII. In this example, seek: What colleges are in Virginia? Notice the answer is vague and does not include information about specific colleges in that area.","title":"Seek a Query"},{"location":"module2/module2-4/module2-4/#inspect-pii","text":"Navigate to the Curate screen in NeuralSeek. Here, we can see that newly created intent with a symbol indicating that this intent contains PII. Expand the intent to view the answers. Notice how the location of \"Virginia\" that we asked in the question is masked to hide the PII.","title":"Inspect PII"},{"location":"module2/module2-4/module2-4/#ask-an-additional-question","text":"Optionally, you can continue to seek queries and view how the related PII is masked in the Curate screen. For example, seek the question, Where is JMU located? . The answer will be vague and not contain information regarding the location due to it containing PII. In the Curate screen, the intent will appear with the same symbol indicating PII. Inside the query, JMU will also be masked to protect the PII.","title":"Ask an Additional Question"},{"location":"module3/module3/","text":"Module 3 - Exploring mAIstro The purpose of Module 3: Exploring mAIstro lies in its multifaceted approach to content generation and retrieval, serving as a dynamic playground for users to engage in free-form content generation, task automation, and #1 in RAG (Retrieval Augmented Generation) for enterprise. This innovative platform facilitates dynamic content retrieval, ensuring flexibility and adaptability in output, and enables users to seamlessly interact with their preferred Large Language Model (LLM). Noteworthy is mAIstro's capability to enhance data quality through features such as summarization, stopwords removal, and keyword extraction, all while providing expert guidance on LLM prompt syntax and base weighting. Whether users aim to refine content within an editor or generate polished documents directly to a Word file, mAIstro excels in delivering a robust and user-centric experience, all with no code required. Level: Advanced Time: 20 minutes No Code Required","title":"Overview"},{"location":"module3/module3/#module-3-exploring-maistro","text":"The purpose of Module 3: Exploring mAIstro lies in its multifaceted approach to content generation and retrieval, serving as a dynamic playground for users to engage in free-form content generation, task automation, and #1 in RAG (Retrieval Augmented Generation) for enterprise. This innovative platform facilitates dynamic content retrieval, ensuring flexibility and adaptability in output, and enables users to seamlessly interact with their preferred Large Language Model (LLM). Noteworthy is mAIstro's capability to enhance data quality through features such as summarization, stopwords removal, and keyword extraction, all while providing expert guidance on LLM prompt syntax and base weighting. Whether users aim to refine content within an editor or generate polished documents directly to a Word file, mAIstro excels in delivering a robust and user-centric experience, all with no code required. Level: Advanced Time: 20 minutes No Code Required","title":"Module 3 - Exploring mAIstro"},{"location":"module3/module3-1/module3-1/","text":"Users will walk through an initial tour of mAIstro to learn how to effectively configure different nodes, modify natural language prompts to the Large Language Model, and generate content within the mAIstro's unique editors. Visual Editor The Visual Editor is the easiest way to use mAIstro. In the Visual Editor, nodes connect horizontally (called chains) and vertically. Nodes are executed starting in the upper left. As the execution runs, for each vertical level any chain existing at that level will be evaluated before continuing down. Add a Node On the sidebar menu, navigate to the Get Data section. Click on the Website Text node. The node will populate as a box inside the Visual Editor. Configure the Website Text Node Click on the node box, and a properties panel will appear on the side. Add a URL to the configuration, for example: https://neuralseek.com . Add a Second Node On the sidebar menu, navigate to the Generate Data section. Click on the Send to LLM node. The new node will populate as a box inside the Visual Editor. Chain the LLM Node Click on the LLM node, and drag it to attach to the right side of the Website Text node, forming a chain. Configure the LLM Node By clicking on the node, a properties panel will appear. Add a prompt inside the panel to make a bullet list from our scraped website. For example: Create a bulleted list of the major topics from the documentation below. Add a Third Node On the sidebar menu, navigate to the Generate Data section. Click on the Send to LLM node. The new node will populate as a box inside the Visual Editor. Configure the LLM Node Notice how the second LLM node populated below the horizontal chain. Click on the node and a properties panel will appear. Add a prompt inside the panel to make a LinkedIn post based on the bulleted list generated from the scraped website. For example: Create a LinkedIn post based on the bulleted list below. Use lots of hashtags. Evaluate the mAIstro Flow Let's run our flow! Click the blue Evaluate button on the bottom bar. Your generated content appears in this panel. Download Generated Contents Optionally, you can also download it in MS Word or CSV formats. Click the Microsoft Word option next to Output Format to download the newly generated content as an MS Word document. Debug the Flow Click on the bug icon in the top right corner to see the full path of the evaluation, plus all the context variables. Click on each step to expand the full evaluation. Step #1: web Notice the contents generated from the scrape of the given URL, in this example https://neuralseek.com . Step #2: LLM Notice the chain link icon next to this step to indicate that this is a chained node. The contents generated show a bulleted list of major topics from the documentation that was pulled from the scraped website, just as the prompt indicates. Step #3: LLM Notice the contents generated here are the same as the resulting contents from clicking the Evaluate button. This is due to it being the final step in the flow. The generated contents show a LinkedIn blog post with lots of hashtags based on the bulleted list of major features generated in Step #2, just as the prompt indicates. Save the Template You can save templates for future use and to call by name via the API by clicking on the Save button on the bottom bar. Add a unique name to the template, for example: Lab_Tour . Optionally add a unique description for ease of navigation. For example: A LinkedIn post based on a list of features from NeuralSeek's website. . You can also download an OpenAPI spec of the flow with all the required parameters to easily import into other tools, like a virtual agent, by clicking on the Generate OpenAPI Spec button on the bottom bar. Continue to Explore This covers the basics of the mAIstro. Click Next to continue to the wide variety of output generation with various example templates, data selection options, modifications to the data, and unique generative data prompts on NeuralSeek's mAIstro platform.","title":"3.1 - mAIstro Tour"},{"location":"module3/module3-1/module3-1/#visual-editor","text":"The Visual Editor is the easiest way to use mAIstro. In the Visual Editor, nodes connect horizontally (called chains) and vertically. Nodes are executed starting in the upper left. As the execution runs, for each vertical level any chain existing at that level will be evaluated before continuing down.","title":"Visual Editor"},{"location":"module3/module3-1/module3-1/#add-a-node","text":"On the sidebar menu, navigate to the Get Data section. Click on the Website Text node. The node will populate as a box inside the Visual Editor.","title":"Add a Node"},{"location":"module3/module3-1/module3-1/#configure-the-website-text-node","text":"Click on the node box, and a properties panel will appear on the side. Add a URL to the configuration, for example: https://neuralseek.com .","title":"Configure the Website Text Node"},{"location":"module3/module3-1/module3-1/#add-a-second-node","text":"On the sidebar menu, navigate to the Generate Data section. Click on the Send to LLM node. The new node will populate as a box inside the Visual Editor.","title":"Add a Second Node"},{"location":"module3/module3-1/module3-1/#chain-the-llm-node","text":"Click on the LLM node, and drag it to attach to the right side of the Website Text node, forming a chain.","title":"Chain the LLM Node"},{"location":"module3/module3-1/module3-1/#configure-the-llm-node","text":"By clicking on the node, a properties panel will appear. Add a prompt inside the panel to make a bullet list from our scraped website. For example: Create a bulleted list of the major topics from the documentation below.","title":"Configure the LLM Node"},{"location":"module3/module3-1/module3-1/#add-a-third-node","text":"On the sidebar menu, navigate to the Generate Data section. Click on the Send to LLM node. The new node will populate as a box inside the Visual Editor.","title":"Add a Third Node"},{"location":"module3/module3-1/module3-1/#configure-the-llm-node_1","text":"Notice how the second LLM node populated below the horizontal chain. Click on the node and a properties panel will appear. Add a prompt inside the panel to make a LinkedIn post based on the bulleted list generated from the scraped website. For example: Create a LinkedIn post based on the bulleted list below. Use lots of hashtags.","title":"Configure the LLM Node"},{"location":"module3/module3-1/module3-1/#evaluate-the-maistro-flow","text":"Let's run our flow! Click the blue Evaluate button on the bottom bar. Your generated content appears in this panel.","title":"Evaluate the mAIstro Flow"},{"location":"module3/module3-1/module3-1/#download-generated-contents","text":"Optionally, you can also download it in MS Word or CSV formats. Click the Microsoft Word option next to Output Format to download the newly generated content as an MS Word document.","title":"Download Generated Contents"},{"location":"module3/module3-1/module3-1/#debug-the-flow","text":"Click on the bug icon in the top right corner to see the full path of the evaluation, plus all the context variables. Click on each step to expand the full evaluation. Step #1: web Notice the contents generated from the scrape of the given URL, in this example https://neuralseek.com . Step #2: LLM Notice the chain link icon next to this step to indicate that this is a chained node. The contents generated show a bulleted list of major topics from the documentation that was pulled from the scraped website, just as the prompt indicates. Step #3: LLM Notice the contents generated here are the same as the resulting contents from clicking the Evaluate button. This is due to it being the final step in the flow. The generated contents show a LinkedIn blog post with lots of hashtags based on the bulleted list of major features generated in Step #2, just as the prompt indicates.","title":"Debug the Flow"},{"location":"module3/module3-1/module3-1/#save-the-template","text":"You can save templates for future use and to call by name via the API by clicking on the Save button on the bottom bar. Add a unique name to the template, for example: Lab_Tour . Optionally add a unique description for ease of navigation. For example: A LinkedIn post based on a list of features from NeuralSeek's website. . You can also download an OpenAPI spec of the flow with all the required parameters to easily import into other tools, like a virtual agent, by clicking on the Generate OpenAPI Spec button on the bottom bar.","title":"Save the Template"},{"location":"module3/module3-1/module3-1/#continue-to-explore","text":"This covers the basics of the mAIstro. Click Next to continue to the wide variety of output generation with various example templates, data selection options, modifications to the data, and unique generative data prompts on NeuralSeek's mAIstro platform.","title":"Continue to Explore"},{"location":"module3/module3-2/module3-2/","text":"NeuralSeek's mAIstro offers several adaptable example templates with a variety of capabilities best suited to your use case. Load Template The introductory screen of NeuralSeek's mAIstro feature will show the options for Example Templates and User Templates . Click on Examples Templates , then choose the Write a Memo option. If you have navigated out of the introductory screen, then click the Load button at the bottom of the screen to access the same options. Populated Nodes Inside the Visual Editor, the example flow will populate and show three nodes. Let's explore these further. Text Node The first node of the template flow is a Text node. Click on the node box to show the properties panel. Inside, is a pre-written prompt in natural language that states Write a memo to staff discussing the following capabilites: . KB Search Node The second node of the template flow is a KB Search node. Click on the node box to show the properties panel. Using keywords, run a query directly against the connected KnowledgeBase. In this example, we'll replace \"cognos analytics\" with filtering . Send to LLM Node The third node of the template flow is a Send to LLM node. Evaluate the mAIstro Flow Let's run our flow! Click the blue Evaluate button on the bottom bar. Notice the generated content appears in the lower panel, including a header, subject line, bulleted key features, and a few paragraphs of text. Configure the LLM Node Click on the Send to LLM node to show the properties panel. Using natural language, optionally prepend an additional prompt to the Large Language Model. For example, add Limit to one paragraph . Click the blue Evaluate button to generate a new output. Notice that this output is significantly shorter and formatted as a single paragraph. Debug the Flow Click on the bug icon in the top right corner to see the full path of the evaluation, plus all the context variables. Click on each step to expand the full evaluation. Step #1: text The natural language prompt is shown. Step #2: kb The contents generated show the resulting information pulled from our source documentation based on the prompted query. Step #3: LLM Notice the contents generated here are the same as the resulting contents from clicking the Evaluate button. This is due to it being the final step in the flow. The generated contents show a one paragraph memo to our staff based on the contents generated in Step #2, just as the prompt indicates. Download Generated Contents Optionally, you can also download it in MS Word or CSV formats. Click the Microsoft Word option next to Output Format to download the newly generated content as an MS Word document.","title":"3.2 - Example Templates"},{"location":"module3/module3-2/module3-2/#load-template","text":"The introductory screen of NeuralSeek's mAIstro feature will show the options for Example Templates and User Templates . Click on Examples Templates , then choose the Write a Memo option. If you have navigated out of the introductory screen, then click the Load button at the bottom of the screen to access the same options.","title":"Load Template"},{"location":"module3/module3-2/module3-2/#populated-nodes","text":"Inside the Visual Editor, the example flow will populate and show three nodes. Let's explore these further.","title":"Populated Nodes"},{"location":"module3/module3-2/module3-2/#text-node","text":"The first node of the template flow is a Text node. Click on the node box to show the properties panel. Inside, is a pre-written prompt in natural language that states Write a memo to staff discussing the following capabilites: .","title":"Text Node"},{"location":"module3/module3-2/module3-2/#kb-search-node","text":"The second node of the template flow is a KB Search node. Click on the node box to show the properties panel. Using keywords, run a query directly against the connected KnowledgeBase. In this example, we'll replace \"cognos analytics\" with filtering .","title":"KB Search Node"},{"location":"module3/module3-2/module3-2/#send-to-llm-node","text":"The third node of the template flow is a Send to LLM node.","title":"Send to LLM Node"},{"location":"module3/module3-2/module3-2/#evaluate-the-maistro-flow","text":"Let's run our flow! Click the blue Evaluate button on the bottom bar. Notice the generated content appears in the lower panel, including a header, subject line, bulleted key features, and a few paragraphs of text.","title":"Evaluate the mAIstro Flow"},{"location":"module3/module3-2/module3-2/#configure-the-llm-node","text":"Click on the Send to LLM node to show the properties panel. Using natural language, optionally prepend an additional prompt to the Large Language Model. For example, add Limit to one paragraph . Click the blue Evaluate button to generate a new output. Notice that this output is significantly shorter and formatted as a single paragraph.","title":"Configure the LLM Node"},{"location":"module3/module3-2/module3-2/#debug-the-flow","text":"Click on the bug icon in the top right corner to see the full path of the evaluation, plus all the context variables. Click on each step to expand the full evaluation. Step #1: text The natural language prompt is shown. Step #2: kb The contents generated show the resulting information pulled from our source documentation based on the prompted query. Step #3: LLM Notice the contents generated here are the same as the resulting contents from clicking the Evaluate button. This is due to it being the final step in the flow. The generated contents show a one paragraph memo to our staff based on the contents generated in Step #2, just as the prompt indicates.","title":"Debug the Flow"},{"location":"module3/module3-2/module3-2/#download-generated-contents","text":"Optionally, you can also download it in MS Word or CSV formats. Click the Microsoft Word option next to Output Format to download the newly generated content as an MS Word document.","title":"Download Generated Contents"}]}